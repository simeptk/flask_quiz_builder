{
  "google_cloud_architect_questions": [
    {
      "id": "1",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company is migrating a legacy on-premises application that consists of a monolithic Java application and a large Oracle database. The application is critical and requires minimal downtime during migration. The database is several terabytes in size. You need to choose a migration strategy and target Google Cloud services.\n\nWhich approach minimizes downtime for the database migration while moving to a managed database service on Google Cloud?",
      "options": {
        "a": "Perform a logical dump and restore of the Oracle database to Cloud SQL for PostgreSQL.",
        "b": "Use Database Migration Service (DMS) to replicate data from the on-premises Oracle database to Cloud SQL for PostgreSQL.",
        "c": "Use `gsutil` to copy database backup files to Cloud Storage and restore them to a Compute Engine VM running Oracle.",
        "d": "Use the BigQuery Data Transfer Service to ingest data directly from the on-premises Oracle database."
      },
      "correct_answer": "b",
      "explanation": "DMS supports online migration from Oracle (and other sources) to Cloud SQL, minimizing downtime by replicating changes during the migration process."
    },
    {
      "id": "2",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A web application experiences unpredictable traffic spikes throughout the day. You need to ensure the application remains responsive under load and minimize costs during low traffic periods. The application is currently running on a single Compute Engine VM.\n\nWhich architecture pattern on Google Cloud would best address these requirements?",
      "options": {
        "a": "Migrate to Cloud Functions for the application logic and Cloud Firestore for the database.",
        "b": "Deploy the application on a single large Compute Engine VM with increased CPU and memory.",
        "c": "Deploy the application on a Managed Instance Group (MIG) with autoscaling and a Load Balancer.",
        "d": "Containerize the application and deploy it on a GKE cluster with fixed-size node pools."
      },
      "correct_answer": "c",
      "explanation": "MIGs with autoscaling automatically adjust the number of VM instances based on traffic, ensuring responsiveness during spikes and cost savings during low periods. A Load Balancer distributes traffic across instances."
    },
    {
      "id": "3",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data processing pipeline that needs to handle large volumes of streaming data and perform complex transformations before storing the results for analysis. Low latency processing is critical.\n\nWhich combination of Google Cloud services is most appropriate for this pipeline?",
      "options": {
        "a": "Cloud Pub/Sub -> Cloud Functions -> Cloud Storage",
        "b": "Cloud Pub/Sub -> Dataflow (Streaming) -> BigQuery",
        "c": "Cloud Storage (staging) -> Dataproc (batch) -> BigQuery",
        "d": "Cloud Pub/Sub -> Compute Engine VMs -> Cloud SQL"
      },
      "correct_answer": "b",
      "explanation": "Cloud Pub/Sub is a scalable messaging service for streaming data. Dataflow is ideal for complex, low-latency streaming transformations. BigQuery is a data warehouse for large-scale analysis."
    },
    {
      "id": "4",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A financial services company needs to store customer transaction data for 7 years for compliance purposes. The data is accessed infrequently after the first 30 days but must be readily available when needed. Cost optimization for storage is a key requirement.\n\nWhich Google Cloud Storage class is most cost-effective for this use case?",
      "options": {
        "a": "Standard",
        "b": "Nearline",
        "c": "Coldline",
        "d": "Archive"
      },
      "correct_answer": "c",
      "explanation": "Coldline is suitable for data accessed less than once a quarter (90 days) and offers very low storage cost, though retrieval costs and latency are higher than Standard or Nearline. Archive is for data accessed less than once a year."
    },
    {
      "id": "5",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are planning a lift-and-shift migration of several applications running on VMware vSphere on-premises to Google Cloud. You want to minimize changes to the existing VM images and management tooling initially.\n\nWhich Google Cloud service is designed to facilitate this type of migration?",
      "options": {
        "a": "Migrate to Virtual Machines (formerly Velostrata)",
        "b": "Transfer Appliance",
        "c": "Storage Transfer Service",
        "d": "Anthos"
      },
      "correct_answer": "a",
      "explanation": "Migrate to Virtual Machines is specifically designed for migrating VMs from environments like VMware, AWS, Azure, or on-premises KVM into Compute Engine, often with minimal changes to the VM image."
    },
    {
      "id": "6",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your application requires a relational database that can handle millions of requests per second with low latency and global reach. Data consistency is paramount.\n\nWhich Google Cloud database service is the best fit?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "BigQuery"
      },
      "correct_answer": "b",
      "explanation": "Cloud Spanner is a globally distributed, strongly consistent, and highly available relational database service, designed for mission-critical applications requiring high throughput and low latency."
    },
    {
      "id": "7",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a solution for storing and analyzing IoT sensor data. The data arrives as a high-velocity stream of small JSON messages. You need to perform real-time analysis and store the raw data for future batch processing.\n\nWhich architecture pattern is most suitable?",
      "options": {
        "a": "Ingest via Cloud Pub/Sub, process with Cloud Functions, store in Cloud Storage. Analyze Cloud Storage data with Dataproc.",
        "b": "Ingest via Cloud Pub/Sub, process with Dataflow (Streaming) for real-time analysis into BigQuery, write raw data to Cloud Storage from Dataflow.",
        "c": "Ingest via HTTP endpoint on Compute Engine, write directly to Cloud SQL. Analyze Cloud SQL with custom scripts.",
        "d": "Ingest via Cloud IoT Core (deprecated, but might appear in older questions/concepts) -> Cloud Pub/Sub -> Bigtable for real-time lookups. Store raw data in Cloud Storage."
      },
      "correct_answer": "b",
      "explanation": "Pub/Sub handles high-velocity streams. Dataflow can perform both real-time processing (into BigQuery) and sink raw data to Cloud Storage. BigQuery is excellent for real-time and batch analysis."
    },
    {
      "id": "8",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company wants to build a new microservices application. Each microservice should be independently deployable and scalable. You need a platform that provides orchestration, service discovery, and scaling capabilities.\n\nWhich Google Cloud service is the best choice for hosting these microservices?",
      "options": {
        "a": "Compute Engine VMs",
        "b": "App Engine Standard",
        "c": "Cloud Functions",
        "d": "Google Kubernetes Engine (GKE)"
      },
      "correct_answer": "d",
      "explanation": "GKE is a managed Kubernetes service that provides robust orchestration, scaling, self-healing, and service discovery features, making it ideal for deploying and managing microservices."
    },
    {
      "id": "9",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a highly available application that needs to span multiple regions for disaster recovery. The application uses a regional managed database service.\n\nHow can you ensure the database is available in a secondary region for failover?",
      "options": {
        "a": "Use a single regional database instance and rely on Google's infrastructure for cross-region failover.",
        "b": "Set up cross-region replication for the managed database service (if supported).",
        "c": "Manually back up the database in the primary region and restore it in the secondary region periodically.",
        "d": "Deploy the application in both regions and use a global load balancer to direct traffic to the active region. The database will handle replication automatically."
      },
      "correct_answer": "b",
      "explanation": "Many managed database services like Cloud SQL (PostgreSQL/MySQL) and Cloud Spanner offer cross-region replication features specifically for disaster recovery and high availability across regions."
    },
    {
      "id": "10",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company has a strict budget and wants to minimize costs for compute resources used for non-production environments (development, testing). These environments do not require 24/7 availability and can tolerate occasional preemption.\n\nWhich Compute Engine pricing model is most suitable for these environments?",
      "options": {
        "a": "Standard VMs",
        "b": "Preemptible VMs (now Spot VMs)",
        "c": "Sustained Usage Discounts",
        "d": "Committed Use Discounts"
      },
      "correct_answer": "b",
      "explanation": "Spot VMs (formerly Preemptible VMs) offer significantly lower prices in exchange for being subject to preemption. This is ideal for fault-tolerant workloads like development/testing where downtime is acceptable."
    },
    {
      "id": "11",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a solution for storing large media files (videos, images) that will be accessed frequently by users globally with low latency. You also need to serve these files efficiently.\n\nWhich services should you use?",
      "options": {
        "a": "Store in Cloud Storage (Standard), serve via Cloud CDN.",
        "b": "Store in Cloud Storage (Archive), serve directly from the bucket URL.",
        "c": "Store in Compute Engine Persistent Disks, serve via a web server on the VM.",
        "d": "Store in Cloud Filestore, serve via Cloud Load Balancing."
      },
      "correct_answer": "a",
      "explanation": "Cloud Storage (Standard) provides low-latency access. Cloud CDN caches content close to users globally, reducing latency and origin load, which is perfect for serving media files."
    },
    {
      "id": "12",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your organization needs to process a large dataset (petabytes) using Apache Spark. The processing is a batch job that runs daily. You want a managed service that handles cluster provisioning and scaling.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Compute Engine (manual cluster setup)",
        "b": "Google Kubernetes Engine (GKE)",
        "c": "Dataproc",
        "d": "Dataflow"
      },
      "correct_answer": "c",
      "explanation": "Dataproc is a managed service for Apache Spark, Hadoop, and other big data frameworks. It simplifies cluster provisioning, scaling, and management, making it ideal for large-scale batch processing jobs."
    },
    {
      "id": "13",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data lake architecture. You need a scalable, cost-effective storage solution that can store structured, semi-structured, and unstructured data in its raw format, suitable for various downstream processing engines.\n\nWhich Google Cloud service is the foundational component for this data lake?",
      "options": {
        "a": "BigQuery",
        "b": "Cloud SQL",
        "c": "Cloud Storage",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "c",
      "explanation": "Cloud Storage is an exabyte-scale, durable, and cost-effective object storage service that can store any type of data format, making it the ideal foundation for a data lake."
    },
    {
      "id": "14",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A company is migrating an application that relies heavily on shared file system access between multiple servers. You need a managed service on Google Cloud that provides NFS file shares for your Compute Engine VMs.\n\nWhich service should you use?",
      "options": {
        "a": "Cloud Storage",
        "b": "Persistent Disks",
        "c": "Cloud Filestore",
        "d": "Google Drive"
      },
      "correct_answer": "c",
      "explanation": "Cloud Filestore is a managed Network Attached Storage (NAS) service for Google Cloud, providing NFS file shares that can be accessed by Compute Engine VMs and GKE clusters."
    },
    {
      "id": "15",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a disaster recovery plan for a critical application running on Compute Engine VMs in a single region. The Recovery Time Objective (RTO) is 4 hours, and the Recovery Point Objective (RPO) is 1 hour.\n\nWhich DR strategy is most appropriate?",
      "options": {
        "a": "Backup and Restore (cold standby)",
        "b": "Pilot Light",
        "c": "Warm Standby",
        "d": "Hot Standby (multi-region active-active)"
      },
      "correct_answer": "c",
      "explanation": "With an RTO of 4 hours and RPO of 1 hour, a Warm Standby is suitable. This involves having a minimal set of resources (like a database replica) running in the DR region and periodically replicating data (RPO). Full application resources are spun up during failover (RTO)."
    },
    {
      "id": "16",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your application requires processing tasks that are triggered by messages arriving in a queue. The tasks are short-lived and have variable processing times. You want a fully managed, cost-effective solution that scales automatically based on the number of messages.\n\nWhich service is the best fit for processing these tasks?",
      "options": {
        "a": "Compute Engine VMs in a MIG",
        "b": "Google Kubernetes Engine (GKE)",
        "c": "Cloud Functions",
        "d": "Cloud Run"
      },
      "correct_answer": "c",
      "explanation": "Cloud Functions is a serverless execution environment that runs your code in response to events (like Pub/Sub messages). It automatically scales based on the number of incoming events and you only pay for the compute time consumed."
    },
    {
      "id": "17",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a new application that requires a NoSQL document database with strong consistency and real-time synchronization capabilities for mobile and web clients.\n\nWhich Google Cloud database service is the best choice?",
      "options": {
        "a": "Cloud Bigtable",
        "b": "Cloud Datastore (now part of Firestore)",
        "c": "Cloud Firestore",
        "d": "BigQuery"
      },
      "correct_answer": "c",
      "explanation": "Cloud Firestore is a serverless, NoSQL document database designed for mobile, web, and server development. It offers real-time synchronization, offline support, and strong consistency."
    },
    {
      "id": "18",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company is migrating a large number of legacy applications to Google Cloud. You need a strategy to group resources, apply consistent policies, and manage access across these applications in an organized manner.\n\nWhich feature of the Google Cloud resource hierarchy is designed for this purpose?",
      "options": {
        "a": "Projects",
        "b": "Folders",
        "c": "Organizations",
        "d": "Labels"
      },
      "correct_answer": "b",
      "explanation": "Folders in the Google Cloud resource hierarchy allow you to group projects logically, enabling you to apply policies (IAM, Organization Policies) at a level above individual projects for centralized management."
    },
    {
      "id": "19",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to estimate the cost of running a specific workload on Compute Engine VMs for a month. You know the required machine type, number of instances, and expected usage hours.\n\nWhich Google Cloud tool should you use?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Billing Reports",
        "c": "Pricing Calculator",
        "d": "Cost Explorer"
      },
      "correct_answer": "c",
      "explanation": "The Google Cloud Pricing Calculator is the tool specifically designed for estimating the cost of Google Cloud products based on configuration and usage projections."
    },
    {
      "id": "20",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a system that involves multiple microservices communicating asynchronously. You need a messaging service that can decouple producers and consumers, handle message buffering, and scale to accommodate high throughput.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Cloud Tasks",
        "b": "Cloud Pub/Sub",
        "c": "Cloud Scheduler",
        "d": "Service Directory"
      },
      "correct_answer": "b",
      "explanation": "Cloud Pub/Sub is a highly scalable, durable, and global messaging service that enables asynchronous communication between services, effectively decoupling producers and consumers."
    },
    {
      "id": "21",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to establish a secure, dedicated, low-latency connection between your on-premises data center and your Google Cloud VPC network. Bandwidth requirements are high (multiple Gbps).\n\nWhich connectivity option is the most appropriate?",
      "options": {
        "a": "IPsec VPN over the public internet",
        "b": "Direct Peering",
        "c": "Carrier Peering",
        "d": "Cloud Interconnect (Dedicated or Partner)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Interconnect provides high-bandwidth, low-latency connections between your on-premises network and Google Cloud, bypassing the public internet. Dedicated is for direct connection to Google's network, Partner is via a service provider."
    },
    {
      "id": "22",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are configuring network security for a set of Compute Engine VMs. You need to allow inbound SSH access only from a specific range of internal IP addresses within your VPC and outbound access to the internet for software updates.\n\nWhich Google Cloud networking construct should you use to implement these rules?",
      "options": {
        "a": "VPC Network Peering",
        "b": "Shared VPC",
        "c": "Firewall Rules",
        "d": "Network Policy (GKE)"
      },
      "correct_answer": "c",
      "explanation": "VPC Firewall Rules control traffic to and from VM instances based on source/destination IP, protocol, and port. You can define ingress rules for SSH from specific IPs and egress rules allowing outbound traffic."
    },
    {
      "id": "23",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You have a GKE cluster and need to expose a set of pods running a web application to the internet. You require a single external IP address and load balancing across the pods.\n\nWhich Kubernetes Service type should you use?",
      "options": {
        "a": "ClusterIP",
        "b": "NodePort",
        "c": "LoadBalancer",
        "d": "ExternalName"
      },
      "correct_answer": "c",
      "explanation": "A Kubernetes Service of type `LoadBalancer` provisions a Google Cloud Load Balancer (either Network Load Balancer or HTTP(S) Load Balancer depending on annotations) to expose the service externally and distribute traffic to the pods."
    },
    {
      "id": "24",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to store sensitive configuration data (like database passwords and API keys) for your application running on Compute Engine. This data should not be stored directly in code or configuration files on the VM.\n\nWhich Google Cloud service is designed for securely storing and managing secrets?",
      "options": {
        "a": "Cloud Storage",
        "b": "Secret Manager",
        "c": "Environment Variables",
        "d": "Compute Engine Metadata"
      },
      "correct_answer": "b",
      "explanation": "Secret Manager is a dedicated service for storing, managing, and accessing sensitive data like API keys, passwords, and certificates securely. It integrates with IAM for access control and provides versioning."
    },
    {
      "id": "25",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are setting up a Shared VPC network. You have a Host Project containing the VPC network and several Service Projects where applications are deployed. How do you grant a Service Project the ability to create VM instances within the Shared VPC network of the Host Project?",
      "options": {
        "a": "Grant the `compute.networkUser` role to the Service Project's service account on the Host Project.",
        "b": "Grant the `compute.admin` role to the Service Project's service account on the Host Project.",
        "c": "Grant the `owner` role to the Service Project's service account on the Host Project.",
        "d": "Grant the `compute.viewer` role to the Service Project's service account on the Host Project."
      },
      "correct_answer": "a",
      "explanation": "The `compute.networkUser` role is specifically designed to allow principals (like Service Project service accounts) to create and manage resources (like VMs) within a Shared VPC network in a different project (the Host Project)."
    },
    {
      "id": "26",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to configure a Persistent Disk for a Compute Engine VM that requires high throughput and low latency for a database workload. The VM is a general-purpose instance.\n\nWhich Persistent Disk type is recommended?",
      "options": {
        "a": "Standard Persistent Disk",
        "b": "Balanced Persistent Disk",
        "c": "SSD Persistent Disk",
        "d": "Extreme Persistent Disk"
      },
      "correct_answer": "c",
      "explanation": "SSD Persistent Disks offer higher IOPS and throughput compared to Standard Persistent Disks and are suitable for most application and database workloads requiring better performance. Extreme Persistent Disks are for extremely high-performance databases."
    },
    {
      "id": "27",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are deploying a containerized application to Cloud Run. The application needs to access a database hosted on-premises. You have already set up Cloud Interconnect between your VPC and on-premises network.\n\nHow can you configure Cloud Run to connect to the on-premises database?",
      "options": {
        "a": "Cloud Run can connect directly over the public internet if the database has a public IP.",
        "b": "Configure Cloud Run to use a Serverless VPC Access connector to connect to your VPC network.",
        "c": "Deploy the database on a Compute Engine VM in the VPC and connect Cloud Run to that VM.",
        "d": "Cloud Run cannot connect to on-premises resources."
      },
      "correct_answer": "b",
      "explanation": "Serverless VPC Access allows serverless services like Cloud Run, Cloud Functions, and App Engine to connect to resources within your VPC network (and thus, via Cloud Interconnect/VPN, to on-premises resources) using internal IP addresses."
    },
    {
      "id": "28",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to automate the patching of operating systems on a fleet of Compute Engine VMs. You want a managed service that can schedule patching across different groups of VMs and report on compliance.\n\nWhich Google Cloud service is designed for this purpose?",
      "options": {
        "a": "Deployment Manager",
        "b": "Cloud Build",
        "c": "OS Patch Management",
        "d": "Compute Engine Sole-Tenant Nodes"
      },
      "correct_answer": "c",
      "explanation": "OS Patch Management is a service that helps you apply patches to your Compute Engine VMs. It allows you to schedule patch deployments, target specific VMs, and view patch compliance reports."
    },
    {
      "id": "29",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are setting up a hybrid cloud environment. You have resources in your on-premises data center and in Google Cloud. You need a mechanism for services in one environment to discover and communicate with services in the other using internal names.\n\nWhich service can help facilitate hybrid service discovery?",
      "options": {
        "a": "Cloud DNS (Private Zones and Peering)",
        "b": "Cloud Load Balancing",
        "c": "Service Directory",
        "d": "VPC Network Peering"
      },
      "correct_answer": "a",
      "explanation": "Cloud DNS Private Zones with DNS peering allow resources in your VPC (and connected on-prem networks) to resolve internal DNS names, facilitating communication using names instead of IPs in a hybrid setup."
    },
    {
      "id": "30",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are provisioning infrastructure using Infrastructure as Code. You need a declarative language that allows you to define your Google Cloud resources (VMs, networks, databases, etc.) in configuration files.\n\nWhich tool/language is natively supported by Google Cloud for this purpose?",
      "options": {
        "a": "Terraform",
        "b": "Cloud Deployment Manager",
        "c": "Ansible",
        "d": "Chef"
      },
      "correct_answer": "b",
      "explanation": "Cloud Deployment Manager is Google Cloud's native Infrastructure as Code deployment service. It uses declarative configuration files (YAML) to deploy and manage resources."
    },
    {
      "id": "31",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to configure a global HTTP(S) Load Balancer for a web application deployed across multiple regions using Managed Instance Groups. You want to ensure users are directed to the closest healthy backend.\n\nWhich Load Balancing scheme should you use?",
      "options": {
        "a": "Internal Load Balancing",
        "b": "External HTTP(S) Load Balancing",
        "c": "Network Load Balancing",
        "d": "TCP Proxy Load Balancing"
      },
      "correct_answer": "b",
      "explanation": "External HTTP(S) Load Balancing is a global load balancer that distributes HTTP/HTTPS traffic to backends in multiple regions, providing a single global IP and directing users to the closest healthy backend."
    },
    {
      "id": "32",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are using Cloud Storage to store application data. You need to configure object lifecycle management to automatically transition objects to a colder storage class after 30 days and delete them after 365 days.\n\nHow do you configure this?",
      "options": {
        "a": "Manually move/delete objects using `gsutil` scripts.",
        "b": "Configure Object Lifecycle Management rules on the Cloud Storage bucket.",
        "c": "Use Cloud Functions triggered by object creation to schedule transitions/deletions.",
        "d": "Set expiration dates on individual objects."
      },
      "correct_answer": "b",
      "explanation": "Cloud Storage Object Lifecycle Management allows you to define rules based on object age, storage class, or number of versions to automatically transition objects between storage classes or delete them."
    },
    {
      "id": "33",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to deploy a containerized application on Google Cloud, but you require fine-grained control over the underlying infrastructure (e.g., specific machine types, custom OS images, GPU attachment) while still leveraging Kubernetes orchestration.\n\nWhich service provides this flexibility?",
      "options": {
        "a": "Cloud Run",
        "b": "App Engine Standard",
        "c": "Google Kubernetes Engine (GKE)",
        "d": "Compute Engine (running Docker manually)"
      },
      "correct_answer": "c",
      "explanation": "GKE provides the power of Kubernetes orchestration while allowing you to configure the underlying Node Pools, including machine types, OS images, GPUs, and other VM-level settings."
    },
    {
      "id": "34",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are provisioning a large number of Compute Engine VMs using an instance template. You need to run a specific startup script on each VM when it boots for the first time to install software and configure the environment.\n\nHow can you achieve this using the instance template?",
      "options": {
        "a": "Include the script in a custom OS image used by the template.",
        "b": "Use the `startup-script` metadata key in the instance template.",
        "c": "Manually SSH into each VM after creation and run the script.",
        "d": "Use Cloud Build to trigger a script execution on each new VM."
      },
      "correct_answer": "b",
      "explanation": "Compute Engine allows you to specify a `startup-script` in the instance metadata or instance template. This script is executed automatically when the VM instance starts for the first time."
    },
    {
      "id": "35",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to ensure that a critical application running on GKE always has a minimum number of pods running, even during node failures or resource pressure.\n\nWhich Kubernetes feature helps guarantee this?",
      "options": {
        "a": "Horizontal Pod Autoscaler (HPA)",
        "b": "Vertical Pod Autoscaler (VPA)",
        "c": "PodDisruptionBudget (PDB)",
        "d": "Node Auto-provisioning"
      },
      "correct_answer": "c",
      "explanation": "A PodDisruptionBudget (PDB) specifies the minimum number or percentage of replicas in a collection that must be available at all times, protecting against voluntary disruptions like node upgrades or scaling down."
    },
    {
      "id": "36",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application is experiencing high latency. You suspect the bottleneck is in the communication between your front-end service and a backend database. You need to identify where the time is being spent in the request flow.\n\nWhich Google Cloud service is most suitable for distributed tracing?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Monitoring",
        "c": "Cloud Trace",
        "d": "Cloud Profiler"
      },
      "correct_answer": "c",
      "explanation": "Cloud Trace is a distributed tracing system that collects latency data from your applications and presents it in a visual format, helping you understand the request flow and identify performance bottlenecks."
    },
    {
      "id": "37",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You have identified that your Compute Engine VMs are frequently hitting CPU utilization limits, impacting application performance. You need to determine which parts of the application code are consuming the most CPU resources to optimize them.\n\nWhich Google Cloud service can help you analyze CPU usage within your application?",
      "options": {
        "a": "Cloud Trace",
        "b": "Cloud Profiler",
        "c": "Cloud Logging",
        "d": "Cloud Monitoring"
      },
      "correct_answer": "b",
      "explanation": "Cloud Profiler is a statistical profiler that continuously gathers CPU usage and allocation information from your applications, helping you identify the most resource-consuming functions or code paths."
    },
    {
      "id": "38",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your team is performing cost optimization on your Google Cloud infrastructure. You notice significant costs associated with persistent disks attached to development VMs that are only used during business hours.\n\nWhat is the most effective way to reduce costs for these disks?",
      "options": {
        "a": "Delete the disks when not in use.",
        "b": "Change the disk type to Standard Persistent Disk.",
        "c": "Use scheduled snapshots and delete the disks when not needed, recreating them from snapshots.",
        "d": "Reduce the disk size."
      },
      "correct_answer": "c",
      "explanation": "Deleting the persistent disk when the VM is stopped but not needed saves costs, as you only pay for the storage of the snapshots. Recreating from a snapshot is much faster than restoring from a full backup."
    },
    {
      "id": "39",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are reviewing your Google Cloud bill and see high egress traffic costs. You need to understand which services and destinations are generating this traffic to identify potential optimizations.\n\nWhich Google Cloud tool provides detailed breakdowns of costs by service, SKU, and destination?",
      "options": {
        "a": "Pricing Calculator",
        "b": "Billing Reports (Cost Breakdown, Cost Table)",
        "c": "Quotas page",
        "d": "Network monitoring tools in Cloud Monitoring"
      },
      "correct_answer": "b",
      "explanation": "The Billing Reports section in the Google Cloud Console provides detailed breakdowns of your costs, allowing you to analyze spending by service, SKU, project, labels, and destination (for network egress)."
    },
    {
      "id": "40",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application uses Cloud Storage to store user-uploaded content. You need to analyze the access patterns of this data to determine if colder storage classes can be used for older data.\n\nHow can you analyze Cloud Storage access patterns?",
      "options": {
        "a": "Enable Cloud Audit Logs for Cloud Storage and analyze the logs in BigQuery.",
        "b": "Use Cloud Monitoring metrics for Cloud Storage read/write operations.",
        "c": "Enable Storage Insights on the bucket.",
        "d": "Check the \"Last Accessed\" timestamp in the Cloud Storage browser."
      },
      "correct_answer": "c",
      "explanation": "Storage Insights provides managed reports on storage usage and access patterns (like object access time), specifically designed for analyzing data in Cloud Storage for optimization purposes."
    },
    {
      "id": "41",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You have deployed a microservices application on GKE. You observe that some requests are taking longer than expected, but you don't know which specific service is causing the delay. You need to visualize the dependencies and performance of your services.\n\nWhich Google Cloud service can help you understand the service graph and latency?",
      "options": {
        "a": "Cloud Trace",
        "b": "Cloud Profiler",
        "c": "Cloud Logging",
        "d": "Cloud Monitoring (Service Monitoring)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Monitoring's Service Monitoring provides a high-level overview of your microservices, including dependencies and performance metrics like latency, helping you quickly identify which service might be the bottleneck."
    },
    {
      "id": "42",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your batch processing job running on Dataproc is taking too long to complete. You suspect there might be inefficiencies in the Spark code or resource allocation.\n\nWhich tool can help you analyze the performance of your Spark jobs on Dataproc?",
      "options": {
        "a": "Cloud Trace",
        "b": "Cloud Profiler",
        "c": "Dataproc Job UI (Spark UI)",
        "d": "Cloud Logging"
      },
      "correct_answer": "c",
      "explanation": "Dataproc provides access to the native web interfaces of the big data frameworks running on the cluster, such as the Spark UI, which offers detailed insights into job execution, stages, tasks, and resource usage."
    },
    {
      "id": "43",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are optimizing the performance of a web application served by an HTTP(S) Load Balancer. You notice high latency for users far from your primary region.\n\nWhat configuration change on the Load Balancer backend service would help reduce latency for global users?",
      "options": {
        "a": "Increase the instance size of backend VMs.",
        "b": "Configure session affinity.",
        "c": "Enable Cloud CDN on the backend service.",
        "d": "Increase the number of health checks."
      },
      "correct_answer": "c",
      "explanation": "Enabling Cloud CDN caches static and dynamic content at edge locations around the world, serving content closer to users and significantly reducing latency for geographically dispersed users."
    },
    {
      "id": "44",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are reviewing your cost reports and see unexpected data transfer costs between VMs in the same VPC network but in different zones.\n\nWhat is the reason for this cost, and how can you minimize it?",
      "options": {
        "a": "Data transfer between zones within the same region is free. There must be an error.",
        "b": "Data transfer between zones within the same region incurs a cost. Deploy VMs in the same zone when possible for inter-VM communication.",
        "c": "Data transfer between regions incurs a cost. Ensure VMs are in the same region.",
        "d": "Data transfer costs are fixed regardless of location."
      },
      "correct_answer": "b",
      "explanation": "While data transfer *within* the same zone is free, data transfer *between* different zones within the same region incurs a cost. For chatty workloads, co-locating VMs in the same zone can reduce costs, though this must be balanced against high availability requirements."
    },
    {
      "id": "45",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You have a batch processing workload that runs daily and takes several hours. You want to minimize the cost of the Compute Engine VMs used for this workload, which is fault-tolerant and can be interrupted.\n\nWhich pricing model should you recommend?",
      "options": {
        "a": "Standard VMs",
        "b": "Preemptible VMs (now Spot VMs)",
        "c": "VMs with Committed Use Discounts",
        "d": "VMs with Sustained Usage Discounts"
      },
      "correct_answer": "b",
      "explanation": "Spot VMs (formerly Preemptible VMs) are significantly cheaper and ideal for fault-tolerant batch jobs that can be stopped and restarted, as they can be preempted by Google Cloud."
    },
    {
      "id": "46",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You need to analyze query performance and identify bottlenecks in your BigQuery data warehouse.\n\nWhich feature within BigQuery can help you understand query execution plans and stages?",
      "options": {
        "a": "Query History",
        "b": "Query Explanation",
        "c": "BigQuery Monitoring in Cloud Monitoring",
        "d": "BigQuery Audit Logs"
      },
      "correct_answer": "b",
      "explanation": "The Query Explanation feature in the BigQuery console provides detailed information about how BigQuery executed a query, including stages, steps, and estimated processing time, helping you identify performance issues."
    },
    {
      "id": "47",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application relies on a Cloud SQL instance. You observe high CPU utilization on the database instance, leading to slow query performance.\n\nWhat is the most direct action you can take to immediately improve performance related to CPU?",
      "options": {
        "a": "Optimize slow queries.",
        "b": "Increase the storage size of the instance.",
        "c": "Scale up the instance machine type (increase CPU/memory).",
        "d": "Add a read replica."
      },
      "correct_answer": "c",
      "explanation": "While optimizing queries and adding read replicas can help with specific workloads (read traffic), the most direct way to address high CPU utilization on the *primary* instance itself is to scale up the machine type to provide more processing power."
    },
    {
      "id": "48",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are designing a serverless application using Cloud Functions. You anticipate a high volume of requests.\n\nWhat is a key consideration for optimizing the performance and cost of Cloud Functions under high load?",
      "options": {
        "a": "Ensure functions are deployed in multiple regions.",
        "b": "Minimize function execution time and cold starts.",
        "c": "Use larger memory allocations for functions.",
        "d": "Increase the maximum number of instances allowed."
      },
      "correct_answer": "b",
      "explanation": "Cloud Functions scales by creating new instances. Minimizing execution time reduces the compute time billed. Minimizing cold starts (by keeping instances warm) reduces latency under load. Both are crucial for performance and cost optimization in a serverless model."
    },
    {
      "id": "49",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You need to analyze the overall resource utilization (CPU, memory, network) of a fleet of Compute Engine VMs to identify potential rightsizing opportunities (scaling up or down).\n\nWhich Google Cloud service provides these metrics?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Monitoring",
        "d": "Billing Reports"
      },
      "correct_answer": "c",
      "explanation": "Cloud Monitoring collects and provides metrics on resource utilization for various Google Cloud services, including Compute Engine VMs, allowing you to analyze performance and identify optimization opportunities."
    },
    {
      "id": "50",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "A project's costs are consistently exceeding budget. You need to identify the main cost drivers within the project across different services.\n\nWhich feature in the Google Cloud Billing Console is best suited for this analysis?",
      "options": {
        "a": "Billing Reports (filtered by Project)",
        "b": "Cost Recommendations",
        "c": "Budgets",
        "d": "Exporting billing data to BigQuery"
      },
      "correct_answer": "a",
      "explanation": "Billing Reports allow you to filter costs by project and break them down by service, SKU, region, etc., providing a clear view of where money is being spent within that specific project."
    },
    {
      "id": "51",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your company has a strict security policy requiring that sensitive customer data stored in Cloud Storage buckets must be encrypted with keys managed by the organization, not by Google.\n\nWhich encryption method should you use?",
      "options": {
        "a": "Google-managed encryption keys (default)",
        "b": "Customer-managed encryption keys (CMEK)",
        "c": "Customer-supplied encryption keys (CSEK)",
        "d": "Encrypt data before uploading to Cloud Storage."
      },
      "correct_answer": "b",
      "explanation": "CMEK allows you to use encryption keys that you create and manage in Cloud KMS to encrypt your data in services like Cloud Storage, giving you control over key lifecycle and access."
    },
    {
      "id": "52",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to grant a user the ability to manage Compute Engine instances in a specific project but prevent them from managing networking resources (like firewall rules or VPC networks).\n\nWhich IAM role provides the necessary permissions for Compute Engine while restricting network access?",
      "options": {
        "a": "`roles/compute.admin`",
        "b": "`roles/compute.instanceAdmin`",
        "c": "`roles/editor`",
        "d": "`roles/compute.networkAdmin`"
      },
      "correct_answer": "b",
      "explanation": "The `roles/compute.instanceAdmin` role grants permissions to manage Compute Engine instances (start, stop, delete, etc.) but does *not* include permissions to manage network resources, adhering to the principle of least privilege."
    },
    {
      "id": "53",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your security team requires that access to sensitive data in BigQuery datasets and Cloud Storage buckets is restricted based on a user's identity *and* their device's security status (e.g., whether the device is corporate-owned and compliant).\n\nWhich Google Cloud security capability is designed to enforce access based on identity and context?",
      "options": {
        "a": "IAM Conditions",
        "b": "Resource Hierarchy (Folders/Organizations)",
        "c": "VPC Service Controls",
        "d": "Context-Aware Access (part of BeyondCorp Enterprise)"
      },
      "correct_answer": "d",
      "explanation": "Context-Aware Access policies allow you to define fine-grained access controls to Google Cloud resources based on user identity and the context of the request, including device information, location, and IP address."
    },
    {
      "id": "54",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to implement Separation of Duties (SoD) for managing encryption keys in Cloud KMS. One user should be able to create key rings and keys, while a different user should be able to enable/disable key versions.\n\nWhich combination of roles should you assign to achieve this SoD?",
      "options": {
        "a": "User 1: `roles/cloudkms.admin`, User 2: `roles/cloudkms.cryptoKeyEncrypterDecrypter`",
        "b": "User 1: `roles/cloudkms.admin`, User 2: `roles/cloudkms.viewer`",
        "c": "User 1: `roles/cloudkms.admin`, User 2: `roles/cloudkms.cryptoOperator`",
        "d": "User 1: `roles/cloudkms.manager`, User 2: `roles/cloudkms.cryptoOperator`"
      },
      "correct_answer": "d",
      "explanation": "`roles/cloudkms.manager` can create key rings and keys. `roles/cloudkms.cryptoOperator` can manage key versions (enable, disable, destroy), but not create keys. This enforces SoD."
    },
    {
      "id": "55",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization has a sensitive application running on Compute Engine that needs to communicate with a Cloud Storage bucket containing confidential data. You want to prevent this data from being exfiltrated to unauthorized projects or locations, even if the Compute Engine VM is compromised.\n\nWhich Google Cloud security control can establish a security perimeter around these services?",
      "options": {
        "a": "Firewall Rules",
        "b": "IAM Policies",
        "c": "VPC Service Controls",
        "d": "Security Groups"
      },
      "correct_answer": "c",
      "explanation": "VPC Service Controls allow you to create security perimeters around Google Cloud services. They prevent data exfiltration by restricting data movement between services within the perimeter and services outside the perimeter, regardless of IAM permissions."
    },
    {
      "id": "56",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to provide a service account with the ability to read objects from a specific Cloud Storage bucket but prevent it from deleting or writing objects.\n\nWhich IAM role should you grant to the service account on the bucket?",
      "options": {
        "a": "`roles/storage.admin`",
        "b": "`roles/storage.objectAdmin`",
        "c": "`roles/storage.objectViewer`",
        "d": "`roles/storage.legacyBucketReader`"
      },
      "correct_answer": "c",
      "explanation": "The `roles/storage.objectViewer` role grants permissions to list objects and read object data within a bucket, but does not grant permissions to create, update, or delete objects."
    },
    {
      "id": "57",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your security policy dictates that all data stored in Cloud Storage must be encrypted at rest.\n\nWhat action is required to ensure this policy is met?",
      "options": {
        "a": "Data in Cloud Storage is encrypted at rest by default using Google-managed keys. No action is required unless custom keys are needed.",
        "b": "You must manually enable encryption on each bucket using Customer-supplied encryption keys.",
        "c": "You must configure Customer-managed encryption keys (CMEK) for all buckets.",
        "d": "Data is only encrypted if uploaded via the `gsutil encrypted cp` command."
      },
      "correct_answer": "a",
      "explanation": "Google Cloud encrypts all data at rest by default using Google-managed encryption keys. Additional configuration (CMEK or CSEK) is only required if you need control over the encryption keys themselves."
    },
    {
      "id": "58",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to automate the deployment of infrastructure using a service account. The service account needs permissions to create and manage Compute Engine instances, Cloud SQL databases, and set up VPC networks within a specific project.\n\nWhich predefined IAM role, while broad, would cover these permissions for the service account within that project?",
      "options": {
        "a": "`roles/viewer`",
        "b": "`roles/editor`",
        "c": "`roles/owner`",
        "d": "`roles/cloudfunctions.admin`"
      },
      "correct_answer": "b",
      "explanation": "The `roles/editor` role grants permissions to create and manage all resources within a project, except for managing IAM roles and permissions. This would cover the creation and management of VMs, databases, and networks."
    },
    {
      "id": "59",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization requires that all access to Google Cloud resources from outside the corporate network must originate from known, approved IP addresses.\n\nWhich security control can enforce this network-level restriction?",
      "options": {
        "a": "IAM Conditions",
        "b": "VPC Firewall Rules",
        "c": "Organization Policy (Allowed IP ranges)",
        "d": "Security Command Center"
      },
      "correct_answer": "c",
      "explanation": "Organization Policies, specifically constraints related to allowed IP ranges (e.g., `constraints/compute.vmExternalIpAccess`, `constraints/iam.allowedPolicyMemberAuthDomains`), can restrict access to resources based on source IP addresses at the organization, folder, or project level."
    },
    {
      "id": "60",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to store and manage TLS certificates for your web application running behind a Google Cloud Load Balancer. The certificates need to be securely stored and easily referenced by the Load Balancer configuration.\n\nWhich Google Cloud service is designed for this purpose?",
      "options": {
        "a": "Secret Manager",
        "b": "Cloud Storage",
        "c": "Identity-Aware Proxy (IAP)",
        "d": "Certificate Manager (or Load Balancer SSL Certificates)"
      },
      "correct_answer": "d",
      "explanation": "Google Cloud offers Certificate Manager (a centralized service) or the ability to upload SSL certificates directly to the Load Balancer for managing TLS certificates used by Load Balancers."
    },
    {
      "id": "61",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "A developer needs temporary access to a production project to troubleshoot an issue. Granting a permanent role is against security policy.\n\nWhich IAM feature allows granting temporary, time-bound access?",
      "options": {
        "a": "Service Accounts",
        "b": "IAM Recommender",
        "c": "Conditional IAM Bindings (using time conditions)",
        "d": "Organization Policies"
      },
      "correct_answer": "c",
      "explanation": "IAM Conditions allow you to grant role bindings that are only effective under specific circumstances, such as within a certain time window, providing temporary access."
    },
    {
      "id": "62",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You are implementing a security principle where users should only have the minimum permissions necessary to perform their job function.\n\nWhat is this security principle called?",
      "options": {
        "a": "Defense in Depth",
        "b": "Separation of Duties (SoD)",
        "c": "Principle of Least Privilege",
        "d": "Zero Trust"
      },
      "correct_answer": "c",
      "explanation": "The Principle of Least Privilege is a security concept that states that a user, program, or process should be given only the minimum levels of access—or permissions—necessary to perform its job function."
    },
    {
      "id": "63",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to scan your Cloud Storage buckets for sensitive data like personally identifiable information (PII) to ensure compliance with data privacy regulations.\n\nWhich Google Cloud service can help you discover and classify sensitive data?",
      "options": {
        "a": "Security Command Center",
        "b": "Cloud Audit Logs",
        "c": "Data Loss Prevention (DLP) API",
        "d": "Cloud Identity"
      },
      "correct_answer": "c",
      "explanation": "The Data Loss Prevention (DLP) API allows you to discover, classify, and de-identify sensitive data in various Google Cloud services, including Cloud Storage, BigQuery, and Datastore."
    },
    {
      "id": "64",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization requires that all resources in a specific folder must inherit a set of IAM policies and Organization Policies.\n\nHow can you apply policies consistently across all projects within that folder?",
      "options": {
        "a": "Apply policies individually to each project.",
        "b": "Apply policies at the Organization level.",
        "c": "Apply policies at the Folder level.",
        "d": "Use Labels to group projects and apply policies."
      },
      "correct_answer": "c",
      "explanation": "Policies in the Google Cloud resource hierarchy are inherited downwards. Applying policies at the Folder level ensures that all projects within that folder (and any sub-folders) inherit those policies, providing consistency."
    },
    {
      "id": "65",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to configure a custom role for a service account that will only be allowed to list Compute Engine instances and view their properties, but nothing else.\n\nWhich base role should you start with, and which permissions are essential?",
      "options": {
        "a": "Start with `roles/compute.admin`, remove unwanted permissions.",
        "b": "Start with `roles/viewer`, add `compute.instances.list` and `compute.instances.get`.",
        "c": "Start with no roles, add `compute.instances.list` and `compute.instances.get`.",
        "d": "Start with `roles/compute.instanceAdmin`, remove unwanted permissions."
      },
      "correct_answer": "c",
      "explanation": "To create a custom role with *only* view permissions for instances, the principle of least privilege suggests starting with no permissions and adding only the necessary ones (`compute.instances.list` to list instances and `compute.instances.get` to view details of a specific instance)."
    },
    {
      "id": "66",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "Your development team is building a new application that will interact with various Google Cloud APIs (e.g., Cloud Storage, BigQuery). They need to follow best practices for authentication.\n\nWhat is the recommended approach for the application running on a Compute Engine VM to authenticate to Google Cloud APIs without storing credentials directly on the VM?",
      "options": {
        "a": "Store a service account key file on the VM.",
        "b": "Use the VM's default service account and assign appropriate IAM roles to it.",
        "c": "Prompt the user for their Google account credentials.",
        "d": "Use API keys for authentication."
      },
      "correct_answer": "b",
      "explanation": "The recommended practice for VMs (and other Google Cloud resources) is to use service accounts. The VM can be configured to run as a specific service account, and IAM roles are granted to that service account to control its access to other Google Cloud services. This avoids storing sensitive key files."
    },
    {
      "id": "67",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "You are advising a development team on building resilient microservices on Google Cloud.\n\nWhich pattern should you recommend to handle temporary network glitches or service unavailability when one microservice calls another?",
      "options": {
        "a": "Synchronous communication with immediate failure",
        "b": "Asynchronous communication with message queues (e.g., Pub/Sub)",
        "c": "Implementing retry logic and circuit breakers in the client code",
        "d": "Using a monolithic architecture instead of microservices"
      },
      "correct_answer": "c",
      "explanation": "While asynchronous communication (b) improves overall resilience, for synchronous calls that are still necessary, implementing retry logic (with exponential backoff) and circuit breakers in the calling service helps handle transient errors and prevent cascading failures."
    },
    {
      "id": "68",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "A data engineering team needs to run ad-hoc queries against a BigQuery dataset from the command line or within scripts.\n\nWhich command-line tool should they use?",
      "options": {
        "a": "`gcloud`",
        "b": "`gsutil`",
        "c": "`bq`",
        "d": "`kubectl`"
      },
      "correct_answer": "c",
      "explanation": "The `bq` command-line tool is specifically designed for interacting with Google BigQuery, allowing users to run queries, load data, manage datasets and tables, etc."
    },
    {
      "id": "69",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "Your team is developing an application that uses Cloud Storage. They need to test the application's interaction with Cloud Storage locally without incurring costs or requiring network connectivity to Google Cloud.\n\nWhich tool can they use for local development and testing of Cloud Storage interactions?",
      "options": {
        "a": "Cloud Shell",
        "b": "`gsutil` with a local file path",
        "c": "Cloud Storage emulator",
        "d": "A mock library in their application code"
      },
      "correct_answer": "c",
      "explanation": "Google Cloud provides emulators for several services, including Cloud Storage, Pub/Sub, and Datastore/Firestore. These emulators run locally and mimic the behavior of the actual services, allowing for offline development and testing."
    },
    {
      "id": "70",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "You are helping a development team set up a Continuous Integration/Continuous Deployment (CI/CD) pipeline for their application on Google Cloud. They need a managed service to automate builds, tests, and deployments from source code repositories.\n\nWhich Google Cloud service is designed for this purpose?",
      "options": {
        "a": "Cloud Source Repositories",
        "b": "Cloud Build",
        "c": "Cloud Deploy",
        "d": "Google Kubernetes Engine (GKE)"
      },
      "correct_answer": "b",
      "explanation": "Cloud Build is a fully managed CI/CD platform that executes your builds on Google Cloud infrastructure. It can fetch source code, run tests, build containers, and deploy to various Google Cloud services."
    },
    {
      "id": "71",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "A legacy application needs to be migrated to Google Cloud. It has complex dependencies and requires minimal code changes initially (lift and shift). You need a tool that can assess the application's compatibility with Google Cloud and recommend migration strategies.\n\nWhich Google Cloud service or tool can assist with application assessment and migration planning?",
      "options": {
        "a": "Migrate to Virtual Machines",
        "b": "Migration Center",
        "c": "StratoZone (acquired by Google)",
        "d": "Cloud Build"
      },
      "correct_answer": "b",
      "explanation": "Migration Center is Google Cloud's service for discovering, assessing, and planning migrations from various source environments to Google Cloud."
    },
    {
      "id": "72",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "Your operations team needs to manage Compute Engine VMs using scripts that interact with the Google Cloud API. They prefer using a Python library.\n\nWhich Python library should they use?",
      "options": {
        "a": "`boto3` (AWS SDK)",
        "b": "Google Cloud Client Libraries for Python",
        "c": "`requests` library to call REST APIs directly",
        "d": "`apache-beam`"
      },
      "correct_answer": "b",
      "explanation": "Google Cloud provides official client libraries for various programming languages, including Python, which offer idiomatic and efficient ways to interact with Google Cloud services programmatically."
    },
    {
      "id": "73",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "You are advising a team on API design best practices for microservices. They need to ensure their APIs are discoverable, well-documented, and easily consumable by internal and external clients.\n\nWhich Google Cloud service is relevant for managing and publishing APIs?",
      "options": {
        "a": "Cloud Endpoints",
        "b": "Apigee",
        "c": "Service Directory",
        "d": "All of the above (depending on complexity/needs)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Endpoints is for developing, deploying, and managing APIs on Google Cloud infrastructure (App Engine, GKE, Compute Engine). Apigee is a full-lifecycle API management platform for complex needs. Service Directory is a service registry for discovery. All are relevant depending on the specific API management requirements."
    },
    {
      "id": "74",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "A team is migrating a MySQL database from on-premises to Cloud SQL. They need a reliable tool to perform a one-time migration with minimal downtime.\n\nWhich Google Cloud service is suitable for this task?",
      "options": {
        "a": "`mysqldump` and `gcloud sql import`",
        "b": "Database Migration Service (DMS)",
        "c": "Transfer Appliance",
        "d": "`gsutil`"
      },
      "correct_answer": "b",
      "explanation": "DMS is a managed service that simplifies database migrations to Cloud SQL and Spanner, supporting various source databases and offering capabilities for online migrations to minimize downtime."
    },
    {
      "id": "75",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "You need to quickly test a `gcloud` command or a set of commands without installing the Cloud SDK on your local machine.\n\nWhich Google Cloud environment provides a web-based command-line interface with the Cloud SDK pre-installed?",
      "options": {
        "a": "Compute Engine VM",
        "b": "Cloud Shell",
        "c": "Cloud Functions",
        "d": "A local Docker container"
      },
      "correct_answer": "b",
      "explanation": "Cloud Shell is a free, web-based environment with the Google Cloud SDK (including `gcloud`, `gsutil`, `bq`, `kubectl`) and other tools pre-installed, providing easy command-line access to Google Cloud resources."
    },
    {
      "id": "76",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application is experiencing intermittent errors. You need to collect detailed logs from your application instances (running on Compute Engine) and analyze them centrally to identify the root cause.\n\nWhich Google Cloud service is designed for centralized log collection, storage, and analysis?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Logging",
        "d": "Error Reporting"
      },
      "correct_answer": "c",
      "explanation": "Cloud Logging is a fully managed service for collecting, storing, and analyzing logs from Google Cloud services and your applications. You can create log sinks to export logs for further analysis or use Logs Explorer for interactive querying."
    },
    {
      "id": "77",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to be notified immediately if the error rate for your microservice running on Cloud Run exceeds a certain threshold.\n\nWhich Google Cloud service should you use to set up this alert?",
      "options": {
        "a": "Cloud Logging (Log-based metrics and alerts)",
        "b": "Cloud Monitoring (Metrics Explorer and Alerting Policy)",
        "c": "Error Reporting",
        "d": "Cloud Trace"
      },
      "correct_answer": "b",
      "explanation": "Cloud Monitoring allows you to create alerting policies based on metrics (like request count, error rate, latency) from your Google Cloud services, including Cloud Run. You can define conditions and notification channels."
    },
    {
      "id": "78",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application release process requires deploying a new version to a small percentage of users first, observing its performance and error rate, and then gradually rolling it out to the rest of the users.\n\nWhich deployment strategy is this?",
      "options": {
        "a": "Rolling Update",
        "b": "Blue/Green Deployment",
        "c": "Canary Deployment",
        "d": "Big Bang Deployment"
      },
      "correct_answer": "c",
      "explanation": "Canary deployment involves gradually rolling out a new version of an application to a small subset of users (the \"canary\") to test its stability and performance in production before rolling it out more widely."
    },
    {
      "id": "79",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to understand the frequency and details of errors occurring in your application running on GKE. You want a service that automatically groups similar errors and provides context.\n\nWhich Google Cloud service is designed for this?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Profiler",
        "d": "Error Reporting"
      },
      "correct_answer": "d",
      "explanation": "Error Reporting is a service that counts, analyzes, and aggregates application errors. It automatically groups similar errors and provides tools to view details and link back to logs and traces."
    },
    {
      "id": "80",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are managing deployments of a critical application on GKE. You need to ensure that during a rolling update, a minimum number of replicas are always available to handle traffic.\n\nWhich Kubernetes object configuration is relevant here?",
      "options": {
        "a": "HorizontalPodAutoscaler (HPA)",
        "b": "PodDisruptionBudget (PDB)",
        "c": "Deployment Strategy (`rollingUpdate` parameters)",
        "d": "Readiness and Liveness Probes"
      },
      "correct_answer": "c",
      "explanation": "The `rollingUpdate` strategy parameters (`maxUnavailable`, `maxSurge`) in a Kubernetes Deployment directly control the availability of replicas during the update process."
    },
    {
      "id": "81",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to configure health checks for your application running on Compute Engine VMs managed by a Managed Instance Group (MIG) behind a Load Balancer.\n\nWhy are health checks important for reliability in this setup?",
      "options": {
        "a": "They reduce the load on the VMs.",
        "b": "They ensure the Load Balancer only sends traffic to healthy instances.",
        "c": "They automatically patch the VMs.",
        "d": "They provide detailed application logs."
      },
      "correct_answer": "b",
      "explanation": "Health checks are crucial for Load Balancers and MIGs. They probe instances to determine if they are healthy and responsive, and the Load Balancer/MIG will stop sending traffic to unhealthy instances and can initiate their replacement."
    },
    {
      "id": "82",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your team is adopting a Site Reliability Engineering (SRE) approach. They want to proactively test the resilience of their application running on GKE by intentionally injecting failures (e.g., delaying network traffic, terminating pods).\n\nWhat is this practice called?",
      "options": {
        "a": "Penetration Testing",
        "b": "Load Testing",
        "c": "Chaos Engineering",
        "d": "Integration Testing"
      },
      "correct_answer": "c",
      "explanation": "Chaos Engineering is the discipline of experimenting on a system in order to build confidence in that system's capability to withstand turbulent conditions in production."
    },
    {
      "id": "83",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to monitor the performance of individual functions within your serverless application running on Cloud Functions. You want to identify which parts of the code are consuming the most time.\n\nWhich Google Cloud service can help you profile the execution of your Cloud Functions?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Profiler",
        "d": "Stackdriver Debugger"
      },
      "correct_answer": "c",
      "explanation": "Cloud Profiler integrates with Cloud Functions (and other services) to provide continuous profiling of CPU usage, memory allocation, and other performance characteristics within your function's code."
    },
    {
      "id": "84",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "A critical production issue has occurred. You need to quickly debug the state of your application running on Compute Engine VMs without stopping or redeploying it.\n\nWhich Google Cloud service allows you to inspect the state of a running application in production?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Profiler",
        "d": "Cloud Debugger (now part of Cloud Logging Error Reporting)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Debugger allows you to inspect the state of a running application at any code location without stopping or slowing it down. It captures local variables and the call stack."
    },
    {
      "id": "85",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are setting up monitoring for a Cloud SQL instance. You need to track key metrics like CPU utilization, memory usage, disk usage, and database connections to ensure the instance is healthy and performing optimally.\n\nWhere can you find these built-in metrics?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Monitoring",
        "d": "Cloud SQL Admin API"
      },
      "correct_answer": "c",
      "explanation": "Cloud Monitoring automatically collects a wide range of metrics for Google Cloud services, including Cloud SQL, providing dashboards and the ability to set up alerts based on these metrics."
    },
    {
      "id": "86",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application deployment process involves building a container image, pushing it to a registry, and deploying it to GKE. You want to ensure the deployed image is the exact one that was built from a specific source code commit and hasn't been tampered with.\n\nWhich service can help you verify the origin and integrity of your container images?",
      "options": {
        "a": "Artifact Registry",
        "b": "Binary Authorization",
        "c": "Container Analysis",
        "d": "Cloud Build"
      },
      "correct_answer": "b",
      "explanation": "Binary Authorization is a deploy-time security control that ensures only trusted container images are deployed to GKE or Cloud Run by enforcing policies based on attestation and provenance."
    },
    {
      "id": "87",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to provide support staff with limited access to view application logs in Cloud Logging for troubleshooting, but prevent them from exporting or deleting logs.\n\nWhich IAM role on the project or specific log view provides appropriate read-only access to logs?",
      "options": {
        "a": "roles/logging.admin",
        "b": "roles/logging.viewer",
        "c": "roles/logging.configWriter",
        "d": "roles/editor"
      },
      "correct_answer": "b",
      "explanation": "The `roles/logging.viewer` role grants permissions to view logs and log entries, but not to manage log sinks, buckets, or delete logs, adhering to the principle of least privilege for support staff."
    },
    {
      "id": "88",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application is experiencing high latency and errors, and you suspect it's due to resource contention on the underlying VMs (CPU, memory, network). You need to visualize these resource metrics alongside application logs and traces.\n\nWhich Google Cloud service provides integrated dashboards for metrics, logs, and traces?",
      "options": {
        "a": "Google Analytics",
        "b": "Security Command Center",
        "c": "Cloud Operations (formerly Stackdriver)",
        "d": "BigQuery"
      },
      "correct_answer": "d",
      "explanation": "Cloud Operations (which includes Cloud Monitoring, Cloud Logging, Cloud Trace, Error Reporting, and Cloud Profiler) provides an integrated suite of tools with dashboards that can correlate metrics, logs, and traces for comprehensive observability and troubleshooting."
    },
    {
      "id": "89",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are implementing a release process for a critical application. You need a strategy that allows for quick rollback to the previous stable version if the new deployment introduces issues.\n\nWhich deployment strategy inherently supports quick rollback?",
      "options": {
        "a": "Rolling Update",
        "b": "Blue/Green Deployment",
        "c": "Canary Deployment",
        "d": "In-place update"
      },
      "correct_answer": "b",
      "explanation": "In a Blue/Green deployment, the new version (\"Green\") is deployed alongside the old version (\"Blue\"). Traffic is then switched to Green. If issues arise, traffic can be instantly switched back to Blue, providing a fast rollback."
    },
    {
      "id": "90",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are investigating an increase in errors reported by Error Reporting. You need to examine the specific log entries associated with these errors to understand the context and details.\n\nHow would you typically access the relevant log entries from Error Reporting?",
      "options": {
        "a": "Error Reporting provides the full log entry details directly.",
        "b": "Error Reporting provides links back to the corresponding log entries in Cloud Logging.",
        "c": "You need to manually search Cloud Logging using timestamps from Error Reporting.",
        "d": "Error Reporting integrates with Cloud Trace, not Cloud Logging."
      },
      "correct_answer": "b",
      "explanation": "Error Reporting aggregates errors and provides summary views. For detailed context, it includes links that take you directly to the relevant log entries in Cloud Logging, allowing you to see the full log stream around the time of the error."
    },
    {
      "id": "91",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs a database to store player profiles, game state, and inventory. This data is frequently updated and requires low-latency reads/writes globally with strong consistency for critical game state.\n\nWhich Google Cloud database service is the best fit for this core game data?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "b",
      "explanation": "Cloud Spanner is designed for globally distributed, strongly consistent, low-latency relational database workloads at scale, making it ideal for critical game state requiring high availability and consistency across regions."
    },
    {
      "id": "92",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games generates massive amounts of game telemetry data (player actions, events) that arrives as a high-velocity stream. This data needs to be processed in near real-time for analytics and stored for long-term analysis.\n\nWhich combination of services should they use for ingesting and processing this streaming telemetry?",
      "options": {
        "a": "Cloud Storage -> Dataproc -> BigQuery",
        "b": "Cloud Pub/Sub -> Dataflow (Streaming) -> BigQuery",
        "c": "Cloud Functions -> Cloud SQL",
        "d": "Cloud Pub/Sub -> Compute Engine -> Cloud Storage"
      },
      "correct_answer": "b",
      "explanation": "Cloud Pub/Sub handles high-throughput ingestion. Dataflow (Streaming) is suitable for real-time processing and transformations. BigQuery is excellent for storing and analyzing large datasets."
    },
    {
      "id": "93",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to manage user authentication and authorization for their mobile game. They want a service that can handle millions of users, integrate with various identity providers (Google, Facebook, etc.), and provide secure token management.\n\nWhich Google Cloud service is designed for this?",
      "options": {
        "a": "Cloud Identity",
        "b": "Identity Platform (formerly Firebase Authentication)",
        "c": "Cloud IAM",
        "d": "Managed Service for Microsoft Active Directory"
      },
      "correct_answer": "b",
      "explanation": "Identity Platform (or Firebase Authentication, its mobile-focused counterpart) is a customer identity and access management (CIAM) platform that handles user sign-up, sign-in, and integrates with various identity providers, suitable for large-scale consumer applications like games."
    },
    {
      "id": "94",
      "category": "Case Study: Mountkirk Games",
      "text": "The game requires a backend for real-time multiplayer interactions. This backend needs very low latency communication between players and needs to scale dynamically based on the number of active games.\n\nWhich Google Cloud service or pattern is best suited for hosting this real-time multiplayer backend?",
      "options": {
        "a": "Compute Engine VMs with manual scaling",
        "b": "Cloud Functions (due to stateless nature)",
        "c": "Google Kubernetes Engine (GKE) with autoscaling node pools and StatefulSets/Deployments",
        "d": "App Engine Standard"
      },
      "correct_answer": "c",
      "explanation": "GKE provides the orchestration needed for potentially stateful game servers (StatefulSets), combined with autoscaling to handle fluctuating player load. It offers the flexibility and control required for low-latency real-time applications."
    },
    {
      "id": "95",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to store game assets (textures, sounds, models) that are downloaded by the game client. These assets are updated infrequently but must be accessible globally with low latency.\n\nWhich services should they use to store and serve these assets?",
      "options": {
        "a": "Cloud Storage (Standard) and Cloud CDN",
        "b": "Cloud Storage (Archive) and Cloud CDN",
        "c": "Compute Engine Persistent Disks and Load Balancer",
        "d": "Cloud Filestore and VPN"
      },
      "correct_answer": "a",
      "explanation": "Cloud Storage (Standard) provides low latency object storage. Cloud CDN caches these static assets at edge locations worldwide, ensuring fast downloads for players regardless of their location."
    },
    {
      "id": "96",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games is concerned about the security of player transaction data. They need to ensure that sensitive payment information is encrypted both in transit and at rest, and that access is strictly controlled.\n\nWhich combination of security practices and services should they prioritize?",
      "options": {
        "a": "Use HTTPS for in-transit encryption, Cloud Storage default encryption for at-rest. IAM for access control.",
        "b": "Use HTTP for speed, rely on network firewalls. Store data unencrypted for fast access.",
        "c": "Use HTTPS for in-transit, CMEK in Cloud KMS for at-rest encryption. Implement fine-grained IAM roles and potentially VPC Service Controls.",
        "d": "Store data in a private Cloud SQL instance, rely on the VPC network for security."
      },
      "correct_answer": "c",
      "explanation": "HTTPS encrypts data in transit. CMEK provides customer control over at-rest encryption keys for sensitive data. Fine-grained IAM enforces least privilege access. VPC Service Controls can create security perimeters to prevent data exfiltration."
    },
    {
      "id": "97",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games wants to analyze player behavior and game performance to inform design decisions. They need a data warehousing solution that can handle petabytes of telemetry data and support complex analytical queries with fast execution times.\n\nWhich Google Cloud service is the best fit for this analytical workload?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "BigQuery"
      },
      "correct_answer": "d",
      "explanation": "BigQuery is a fully managed, serverless data warehouse designed for large-scale analytical queries, making it ideal for analyzing petabytes of game telemetry data."
    },
    {
      "id": "98",
      "category": "Case Study: Mountkirk Games",
      "text": "During peak gaming events, Mountkirk Games anticipates massive spikes in traffic to their backend services. They need an architecture that can automatically scale compute resources up and down in response to player demand without manual intervention.\n\nWhich Google Cloud services or features are essential for this auto-scaling capability?",
      "options": {
        "a": "Managed Instance Groups (MIGs) with autoscaling, GKE with cluster autoscaler and HPA.",
        "b": "Manual scaling of Compute Engine VMs.",
        "c": "Cloud Functions with fixed memory allocation.",
        "d": "App Engine Standard with manual scaling."
      },
      "correct_answer": "a",
      "explanation": "MIGs with autoscaling automatically adjust VM count. GKE's Cluster Autoscaler adjusts node count, and the Horizontal Pod Autoscaler (HPA) adjusts pod count based on metrics like CPU utilization or custom metrics, providing robust auto-scaling for containerized applications."
    },
    {
      "id": "99",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to implement a CI/CD pipeline for their microservices running on GKE. They want to automate builds, tests, and deployments.\n\nWhich combination of Google Cloud services can provide a comprehensive CI/CD solution?",
      "options": {
        "a": "Cloud Source Repositories, Cloud Build, Cloud Deploy, GKE",
        "b": "GitHub Actions, Jenkins on Compute Engine, manual deployments",
        "c": "Cloud Functions, Cloud Tasks, Cloud Scheduler",
        "d": "App Engine, Cloud Endpoints"
      },
      "correct_answer": "a",
      "explanation": "This combination represents a typical Google Cloud native CI/CD flow: Cloud Source Repositories for source control, Cloud Build for automated builds and tests, Cloud Deploy for managed continuous delivery to GKE, and GKE as the target deployment environment."
    },
    {
      "id": "100",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to monitor the health and performance of their global gaming platform. They require dashboards, alerting, and the ability to drill down into logs and traces when issues occur.\n\nWhich integrated suite of Google Cloud services provides these capabilities?",
      "options": {
        "a": "Google Analytics",
        "b": "Security Command Center",
        "c": "Cloud Operations (formerly Stackdriver)",
        "d": "BigQuery ML"
      },
      "correct_answer": "d",
      "explanation": "Cloud Operations (which includes Cloud Monitoring, Cloud Logging, Cloud Trace, Error Reporting, and Cloud Profiler) provides an integrated suite of tools with dashboards that can correlate metrics, logs, and traces for comprehensive observability of a complex, distributed application like a global gaming platform."
    },
    {
      "id": "101",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games is planning their migration to Google Cloud. They have existing game servers running on-premises that they want to containerize and move to GKE. They need a strategy to minimize downtime for existing players during the transition.\n\nWhich migration approach is most suitable for containerizing and migrating these game servers to GKE with minimal downtime?",
      "options": {
        "a": "Lift and shift the VMs using Migrate to Virtual Machines.",
        "b": "Manually rebuild the servers as containers and perform a big-bang cutover.",
        "c": "Use Migrate to Containers to containerize the existing application and prepare them for deployment on GKE or Anthos, potentially using a phased approach.",
        "d": "Rewrite the entire application as serverless functions."
      },
      "correct_answer": "c",
      "explanation": "Migrate to Containers is a service specifically designed to take existing VM-based applications, containerize them, and prepare them for deployment on GKE or Anthos, facilitating a move to containers with less effort than a manual rewrite and enabling phased cutovers."
    },
    {
      "id": "102",
      "category": "Additional Questions",
      "text": "You are designing a solution for processing highly sensitive data that requires cryptographic operations (encryption, decryption, signing). You need a managed service that provides hardware security modules (HSMs) for key protection and FIPS 140-2 Level 3 compliance.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Cloud KMS (Software keys)",
        "b": "Cloud KMS (Hardware keys - Cloud HSM)",
        "c": "Secret Manager",
        "d": "Compute Engine with third-party HSM software"
      },
      "correct_answer": "b",
      "explanation": "Cloud HSM is a fully managed cloud-hosted hardware security module (HSM) service that allows you to host encryption keys in FIPS 140-2 Level 3 certified HSMs, providing a high level of security for cryptographic operations."
    },
    {
      "id": "103",
      "category": "Additional Questions",
      "text": "Your application needs to process tasks asynchronously based on a schedule (e.g., run a report daily, send emails weekly).\n\nWhich Google Cloud service is designed for triggering scheduled events?",
      "options": {
        "a": "Cloud Pub/Sub",
        "b": "Cloud Tasks",
        "c": "Cloud Scheduler",
        "d": "Workflow"
      },
      "correct_answer": "c",
      "explanation": "Cloud Scheduler is a fully managed enterprise-grade cron job scheduler. It allows you to schedule jobs (HTTP requests, Pub/Sub messages, App Engine tasks) at defined times or intervals."
    },
    {
      "id": "104",
      "category": "Additional Questions",
      "text": "You are designing a data pipeline that involves multiple steps: ingesting data, transforming it, and loading it into a data warehouse. You need a service to orchestrate and manage the dependencies between these steps.\n\nWhich Google Cloud service is suitable for building and managing data pipelines?",
      "options": {
        "a": "Cloud Functions",
        "b": "Cloud Tasks",
        "c": "Cloud Build",
        "d": "Cloud Data Fusion or Cloud Composer (managed Apache Airflow)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Composer is a managed Apache Airflow service that allows you to author, schedule, and monitor workflows (pipelines) programmatically, making it ideal for orchestrating complex data processing tasks."
    },
    {
      "id": "105",
      "category": "Additional Questions",
      "text": "You need to grant a third-party vendor access to upload files to a specific Cloud Storage bucket only, and nothing else. You want to give them credentials that are specific to the service and bucket.\n\nWhich Google Cloud identity type is appropriate for the vendor to use?",
      "options": {
        "a": "A Google Account (user account)",
        "b": "A Service Account",
        "c": "A Google Group",
        "d": "A G Suite/Google Workspace account"
      },
      "correct_answer": "b",
      "explanation": "Service accounts are identities used by applications or services, not human users. You can create a service account specifically for the vendor, grant it permissions only on the target Cloud Storage bucket, and provide the vendor with the service account key."
    },
    {
      "id": "106",
      "category": "Additional Questions",
      "text": "You are deploying a web application on Compute Engine behind a Load Balancer. You need to ensure that user sessions are maintained, directing subsequent requests from the same user to the same backend instance.\n\nWhich Load Balancer feature should you configure?",
      "options": {
        "a": "Health Checks",
        "b": "Autoscaling",
        "c": "Session Affinity",
        "d": "Content-based routing"
      },
      "correct_answer": "c",
      "explanation": "Session affinity configures the Load Balancer to send requests from the same client to the same backend instance, which is necessary for applications that store session state locally on the instance."
    },
    {
      "id": "107",
      "category": "Additional Questions",
      "text": "Your application needs to store time-series data (e.g., sensor readings, metrics) that is written frequently and requires fast lookups by timestamp and identifier. The data is not relational and scales to very high throughput.\n\nWhich Google Cloud database service is most suitable for this high-volume time-series data with lookups by device and time?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "d",
      "explanation": "Cloud Bigtable is optimized for very large operational and analytical workloads, including time-series data and IoT data. Its key-value structure with column families and efficient range scans makes it suitable for querying data by row key (e.g., device ID + timestamp)."
    },
    {
      "id": "108",
      "category": "Additional Questions",
      "text": "You are designing a solution for processing sensitive data that requires de-identification before it can be used for analytics.\n\nWhich Google Cloud service can perform tasks like masking, tokenization, or pseudonymization of sensitive data?",
      "options": {
        "a": "Data Loss Prevention (DLP) API",
        "b": "Cloud KMS",
        "c": "Cloud Identity",
        "d": "Security Command Center"
      },
      "correct_answer": "a",
      "explanation": "The Data Loss Prevention (DLP) API provides powerful methods for inspecting, classifying, and de-identifying sensitive data using techniques like masking, tokenization, format-preserving encryption, and pseudonymization."
    },
    {
      "id": "109",
      "category": "Additional Questions",
      "text": "You need to automate administrative tasks on your Google Cloud resources using scripts that run periodically. The scripts are written in Python and require access to Google Cloud APIs.\n\nWhich serverless compute option is suitable for running these periodic administrative scripts?",
      "options": {
        "a": "Compute Engine VMs",
        "b": "Google Kubernetes Engine (GKE)",
        "c": "Cloud Functions triggered by Cloud Scheduler",
        "d": "Cloud Run"
      },
      "correct_answer": "c",
      "explanation": "Cloud Functions is a good fit for short-lived, event-driven tasks. Cloud Scheduler can trigger a Cloud Function on a schedule, making it a serverless and cost-effective way to run periodic administrative scripts."
    },
    {
      "id": "110",
      "category": "Additional Questions",
      "text": "Your development team is using a third-party Git repository (e.g., GitHub, GitLab). They want to set up a CI/CD pipeline on Google Cloud that triggers builds automatically whenever code is pushed to the repository.\n\nHow can Cloud Build be integrated with the third-party repository?",
      "options": {
        "a": "Cloud Build can only pull from Cloud Source Repositories.",
        "b": "Configure a webhook in the third-party repository to trigger Cloud Build.",
        "c": "Manually trigger Cloud Build builds from the console after each push.",
        "d": "Use a Compute Engine VM to poll the repository for changes."
      },
      "correct_answer": "b",
      "explanation": "Cloud Build can be integrated with external repositories like GitHub and GitLab by setting up webhooks. When code is pushed, the webhook sends a notification to Cloud Build, triggering a build."
    },
    {
      "id": "111",
      "category": "Additional Questions",
      "text": "You need to deploy a containerized application that serves web traffic. The application has variable load, and you want a fully managed service that scales automatically down to zero instances when there is no traffic to minimize costs.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Compute Engine MIG",
        "b": "GKE Autopilot",
        "c": "Cloud Functions",
        "d": "Cloud Run"
      },
      "correct_answer": "d",
      "explanation": "Cloud Run is a fully managed serverless platform for containerized applications. It scales automatically based on requests and can scale down to zero instances, making it very cost-effective for workloads with intermittent traffic."
    },
    {
      "id": "112",
      "category": "Additional Questions",
      "text": "Your compliance requirements state that all administrative activities on Google Cloud resources must be logged and retained for 7 years.\n\nWhich Google Cloud service should you configure to meet this requirement?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Cloud Trace",
        "c": "Cloud Audit Logs",
        "d": "Error Reporting"
      },
      "correct_answer": "c",
      "explanation": "Cloud Audit Logs record administrative activities (Admin Activity logs) and data access (Data Access logs) on your Google Cloud resources. You can configure log sinks to export these logs to Cloud Storage or BigQuery for long-term retention and analysis."
    },
    {
      "id": "113",
      "category": "Additional Questions",
      "text": "You are designing a networking solution for a multi-tier application in your VPC. You have a web tier, an application tier, and a database tier, each running on separate sets of VMs. You need to control traffic flow between these tiers, allowing only necessary communication (e.g., web to app on specific ports, app to DB on specific ports).\n\nWhich Google Cloud networking feature is used to define and enforce these traffic rules between VMs based on tags or service accounts?",
      "options": {
        "a": "VPC Network Peering",
        "b": "Firewall Rules",
        "c": "Routes",
        "d": "Subnets"
      },
      "correct_answer": "b",
      "explanation": "VPC Firewall Rules allow you to define rules that permit or deny traffic to and from VM instances based on various criteria, including source/destination network tags or service accounts, protocols, and ports. This is essential for implementing a segmented network security model."
    },
    {
      "id": "114",
      "category": "Additional Questions",
      "text": "You need to migrate a large volume of data (hundreds of terabytes) from on-premises storage to Cloud Storage, but your internet connection is slow and unreliable.\n\nWhich Google Cloud service or appliance can accelerate this large-scale, offline data transfer?",
      "options": {
        "a": "`gsutil` over your internet connection",
        "b": "Storage Transfer Service (for online transfers)",
        "c": "Transfer Appliance",
        "d": "Cloud Data Fusion"
      },
      "correct_answer": "c",
      "explanation": "Transfer Appliance is a physical hardware appliance provided by Google Cloud that you load with your data on-premises and then ship back to Google for direct upload to Cloud Storage, bypassing slow or unreliable network connections."
    },
    {
      "id": "115",
      "category": "Additional Questions",
      "text": "You are designing a solution for storing and querying sensor data from thousands of devices. Each data point has a timestamp, device ID, and several measurements. Queries will typically involve fetching data for a specific device within a time range. High write throughput is expected.\n\nWhich Google Cloud database service is most suitable for this high-volume time-series data with lookups by device and time?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "d",
      "explanation": "Cloud Bigtable is optimized for very large operational and analytical workloads, including time-series data and IoT data. Its key-value structure with column families and efficient range scans makes it suitable for querying data by row key (e.g., device ID + timestamp)."
    },
    {
      "id": "116",
      "category": "Additional Questions",
      "text": "You need to ensure that your production environment is isolated from your development and staging environments for security and stability.\n\nWhich Google Cloud resource hierarchy pattern is the recommended way to achieve this isolation?",
      "options": {
        "a": "Use different VPC networks within the same project.",
        "b": "Use different projects for each environment (Prod, Stage, Dev).",
        "c": "Use different subnets within the same VPC network.",
        "d": "Use Labels to differentiate resources in the same project."
      },
      "correct_answer": "b",
      "explanation": "Using separate projects for different environments (Prod, Stage, Dev) provides strong isolation boundaries for resources, billing, and IAM policies, which is the recommended practice for environment separation."
    },
    {
      "id": "117",
      "category": "Additional Questions",
      "text": "You are deploying a new version of your application to GKE. You want to ensure that the new version is healthy and serving traffic correctly before decommissioning the old version.\n\nWhich type of readiness probe should you configure for your application pods?",
      "options": {
        "a": "Liveness probe",
        "b": "Startup probe",
        "c": "Readiness probe",
        "d": "Health check"
      },
      "correct_answer": "c",
      "explanation": "A readiness probe indicates whether a container is ready to handle requests. If a readiness probe fails, the endpoints controller removes the pod's IP address from the endpoints of all Services that match the pod, ensuring traffic is not sent to unhealthy pods during deployment or operation."
    },
    {
      "id": "118",
      "category": "Additional Questions",
      "text": "Your application needs to perform background processing tasks that can take several minutes to complete. These tasks are triggered by user actions but don't need to be completed immediately. You need a service that can manage a queue of these tasks and execute them reliably.\n\nWhich Google Cloud service is designed for managing and executing asynchronous tasks?",
      "options": {
        "a": "Cloud Pub/Sub",
        "b": "Cloud Tasks",
        "c": "Cloud Scheduler",
        "d": "Cloud Functions"
      },
      "correct_answer": "b",
      "explanation": "Cloud Tasks is a fully managed service that allows you to manage the execution of a large number of distributed tasks. It provides features like retries, rate limiting, and task de-duplication, making it suitable for reliable background processing."
    },
    {
      "id": "119",
      "category": "Additional Questions",
      "text": "You are setting up monitoring for your application. You need to collect custom metrics from your application code (e.g., number of active users, specific business events).\n\nHow can you send custom metrics to Cloud Monitoring?",
      "options": {
        "a": "Custom metrics cannot be sent to Cloud Monitoring.",
        "b": "Use the Cloud Monitoring API or client libraries within your application.",
        "c": "Send custom metrics as logs to Cloud Logging.",
        "d": "Define custom metrics in the `gcloud` command line."
      },
      "correct_answer": "b",
      "explanation": "Cloud Monitoring provides APIs and client libraries that allow you to define and write custom metrics directly from your application code or infrastructure."
    },
    {
      "id": "120",
      "category": "Additional Questions",
      "text": "You need to design a solution for ingesting data from various sources (databases, files, streams) into BigQuery for analysis. You need a service that provides pre-built connectors and a visual interface for building ETL/ELT pipelines.\n\nWhich Google Cloud service is designed for this purpose?",
      "options": {
        "a": "Dataflow",
        "b": "Dataproc",
        "c": "Cloud Data Fusion",
        "d": "BigQuery Data Transfer Service"
      },
      "correct_answer": "c",
      "explanation": "Cloud Data Fusion is a fully managed, cloud-native data integration service with a web-based UI and a library of preconfigured connectors and transformations for building ETL/ELT pipelines."
    },
    {
      "id": "121",
      "category": "Additional Questions",
      "text": "Your company has a policy that disallows the creation of external IP addresses for Compute Engine VMs in the production environment.\n\nWhich Google Cloud feature can enforce this policy at the organization, folder, or project level?",
      "options": {
        "a": "IAM Policy",
        "b": "Firewall Rule",
        "c": "Organization Policy Constraint",
        "d": "VPC Service Control"
      },
      "correct_answer": "c",
      "explanation": "Organization Policies allow you to define constraints on how Google Cloud resources can be used. The `constraints/compute.vmExternalIpAccess` constraint specifically disallows the creation of VM instances with external IP addresses."
    },
    {
      "id": "122",
      "category": "Additional Questions",
      "text": "You need to perform a security assessment of your Google Cloud environment to identify vulnerabilities and compliance risks (e.g., open firewall ports, public storage buckets, IAM misconfigurations).\n\nWhich Google Cloud service provides a centralized security and data risk platform?",
      "options": {
        "a": "Cloud Audit Logs",
        "b": "Data Loss Prevention (DLP)",
        "c": "Security Command Center",
        "d": "IAM Recommender"
      },
      "correct_answer": "c",
      "explanation": "Security Command Center is a comprehensive security and data risk platform for Google Cloud. It helps you understand your security and data risk surface, prevent, detect, and respond to threats."
    },
    {
      "id": "123",
      "category": "Additional Questions",
      "text": "You are designing a backup strategy for critical data stored in Cloud Storage. You need to ensure data is protected against accidental deletion or tampering and can be restored to a previous state.\n\nWhich Cloud Storage feature helps protect against accidental deletion and allows restoring previous versions of objects?",
      "options": {
        "a": "Lifecycle Management",
        "b": "Signed URLs",
        "c": "Versioning",
        "d": "Object Lock"
      },
      "correct_answer": "c",
      "explanation": "Object Versioning in Cloud Storage keeps multiple versions of an object in the same bucket. This protects against accidental deletion or overwriting and allows you to restore a previous state of an object."
    },
    {
      "id": "124",
      "category": "Additional Questions",
      "text": "You need to deploy an application as a container but require a high degree of control over the container's environment, including namespaces, security context, and resource limits, and want to manage it alongside other containerized applications.\n\nWhich Google Cloud service offers the most control and orchestration capabilities for containers?",
      "options": {
        "a": "Cloud Run",
        "b": "Cloud Functions",
        "c": "Google Kubernetes Engine (GKE)",
        "d": "App Engine Flexible"
      },
      "correct_answer": "c",
      "explanation": "GKE provides the full power of Kubernetes, offering extensive control over container deployment, scaling, networking, security contexts, resource limits, and orchestration features not available in simpler services like Cloud Run or Cloud Functions."
    },
    {
      "id": "125",
      "category": "Additional Questions",
      "text": "Your application generates significant logs. You need to analyze these logs using SQL queries for complex analysis and reporting.\n\nHow can you make your Cloud Logging data queryable using SQL?",
      "options": {
        "a": "Query logs directly in the Cloud Logging Logs Explorer using its query language.",
        "b": "Export logs to BigQuery using a Log Sink.",
        "c": "Export logs to Cloud Storage and query them with Dataproc.",
        "d": "Use Cloud SQL to store and query logs."
      },
      "correct_answer": "b",
      "explanation": "By configuring a Log Sink in Cloud Logging, you can automatically route logs to BigQuery, where they become available as tables that can be queried using standard SQL."
    },
    {
      "id": "1",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare needs to achieve a minimum 99.9% availability for their customer-facing applications running on Kubernetes. They are currently in colocation and migrating to Google Cloud.\n\nWhich Google Cloud architecture should they implement to meet this availability requirement for their containerized applications?",
      "options": {
        "a": "Deploy the Kubernetes cluster in a single zone within a region.",
        "b": "Deploy the Kubernetes cluster across multiple zones within a single region.",
        "c": "Deploy the Kubernetes cluster across multiple regions.",
        "d": "Deploy the Kubernetes cluster on Compute Engine VMs in a single zone."
      },
      "correct_answer": "b",
      "explanation": "To achieve 99.9% availability within a region, deploying across multiple zones is necessary to protect against single-zone failures. Deploying across multiple regions (c) would provide even higher availability (e.g., 99.99%) for disaster recovery, but 99.9% can typically be met regionally with multi-zone deployment and robust application design. Single zone (a) is a single point of failure. Running on single VMs (d) doesn't leverage Kubernetes' built-in availability features."
    },
    {
      "id": "2",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare needs to provide centralized visibility and proactive action on system performance and usage across their applications, including containerized services and databases. Their current monitoring is via open-source tools and ignored alerts.\n\nWhich Google Cloud service should they use for comprehensive monitoring, logging, and alerting?",
      "options": {
        "a": "Cloud Logging and Cloud Monitoring",
        "b": "Security Command Center",
        "c": "Data Loss Prevention (DLP)",
        "d": "BigQuery"
      },
      "correct_answer": "a",
      "explanation": "Cloud Logging is the centralized service for collecting and analyzing logs. Cloud Monitoring provides metrics collection, dashboards, and alerting based on performance and usage data from various Google Cloud services, including GKE and databases. Error Reporting complements this for application errors, and Cloud Trace for distributed tracing."
    },
    {
      "id": "3",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare has legacy file- and API-based integrations on-premises that need to connect securely and with high performance to their new Google Cloud environment. These systems will remain on-premises for several years.\n\nWhich Google Cloud connectivity option should they choose for this hybrid environment?",
      "options": {
        "a": "IPsec VPN over the public internet",
        "b": "Direct Peering",
        "c": "Cloud Interconnect (Dedicated or Partner)",
        "d": "Establish a public IP for on-prem systems and connect over the internet."
      },
      "correct_answer": "c",
      "explanation": "Cloud Interconnect provides a dedicated, high-bandwidth, low-latency connection between on-premises and Google Cloud, bypassing the public internet. This is suitable for high-performance, secure connections required for ongoing hybrid operations with legacy systems. IPsec VPN (a) is generally lower bandwidth and higher latency."
    },
    {
      "id": "4",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare's data is stored in various databases, including relational (MySQL, MS SQL Server) and NoSQL (Redis, MongoDB). They need to migrate this data to Google Cloud.\n\nWhich Google Cloud services are appropriate targets for these databases, prioritizing managed services where possible?",
      "options": {
        "a": "MySQL -> Cloud SQL for MySQL; MS SQL Server -> Compute Engine with SQL Server; Redis -> Memorystore for Redis; MongoDB -> MongoDB Atlas on GCP or self-hosted on Compute Engine/GKE.",
        "b": "Migrate all databases to BigQuery.",
        "c": "MySQL, MS SQL Server -> Cloud Spanner; Redis, MongoDB -> Cloud Firestore.",
        "d": "Migrate all databases to Compute Engine VMs with the original database software installed."
      },
      "correct_answer": "a",
      "explanation": "Cloud SQL is the managed relational database service for MySQL and PostgreSQL. While Cloud SQL for SQL Server exists, lift-and-shift often involves running SQL Server on a Compute Engine VM initially. Memorystore is the managed Redis service. MongoDB is not offered as a native managed service by Google, so running it on GKE/Compute Engine or using a partner solution like MongoDB Atlas on GCP are common approaches."
    },
    {
      "id": "5",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare needs to dynamically scale and provision new environments rapidly due to exponential growth.\n\nWhich Google Cloud services and practices are key to achieving dynamic scaling and rapid provisioning for their containerized applications?",
      "options": {
        "a": "Manual scaling of Compute Engine VMs and shell scripts for provisioning.",
        "b": "Managed Instance Groups (MIGs) with autoscaling and Deployment Manager templates.",
        "c": "Google Kubernetes Engine (GKE) with Cluster Autoscaler and Horizontal Pod Autoscaler (HPA), combined with Infrastructure as Code (e.g., Terraform, Deployment Manager).",
        "d": "App Engine Standard with traffic splitting."
      },
      "correct_answer": "c",
      "explanation": "GKE provides the orchestration for containers. Cluster Autoscaler dynamically adjusts the number of nodes, and HPA adjusts the number of pods based on load, providing dynamic scaling. IaC tools enable rapid and repeatable provisioning of the GKE clusters and related infrastructure."
    },
    {
      "id": "6",
      "category": "Case Study: EHR Healthcare",
      "text": "Maintaining regulatory compliance is critical for EHR Healthcare. They handle sensitive patient data.\n\nWhich Google Cloud security and compliance capabilities are essential considerations for handling Electronic Health Records (EHR) data?",
      "options": {
        "a": "Using default Google-managed encryption, basic IAM roles, and public internet connectivity.",
        "b": "Implementing fine-grained IAM policies, using Customer-Managed Encryption Keys (CMEK) for sensitive data storage, enabling Cloud Audit Logs, and potentially using VPC Service Controls.",
        "c": "Relying solely on network firewalls and VPNs.",
        "d": "Storing all data in Compute Engine Persistent Disks encrypted with default keys."
      },
      "correct_answer": "b",
      "explanation": "Handling sensitive health data requires strict controls. Fine-grained IAM enforces least privilege. CMEK provides organizational control over encryption keys. Cloud Audit Logs provide an immutable record of access. VPC Service Controls can create security perimeters to prevent unauthorized data movement."
    },
    {
      "id": "7",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare wants to decrease infrastructure administration costs and reduce the burden of managing disparate systems.\n\nWhich approach using Google Cloud services aligns with this goal?",
      "options": {
        "a": "Lift-and-shift all applications to Compute Engine VMs and manage them manually.",
        "b": "Leverage managed services like GKE, Cloud SQL, Memorystore, and Cloud Operations, and automate infrastructure provisioning with IaC.",
        "c": "Continue using disparate open-source tools for monitoring and management.",
        "d": "Deploy all applications on App Engine Flex with manual scaling."
      },
      "correct_answer": "b",
      "explanation": "Managed services offload operational overhead (patching, backups, scaling infrastructure). Automating provisioning with IaC reduces manual effort and potential for misconfiguration, directly addressing the goal of decreasing administration costs and improving consistency."
    },
    {
      "id": "8",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL needs to reduce viewer latency for their video streams, especially in emerging markets.\n\nWhich Google Cloud service should they use to cache and serve video content closer to their global audience?",
      "options": {
        "a": "Cloud Storage (Standard)",
        "b": "Cloud CDN",
        "c": "Regional External HTTP(S) Load Balancer",
        "d": "Transfer Appliance"
      },
      "correct_answer": "b",
      "explanation": "Cloud CDN (Content Delivery Network) caches static and dynamic content at edge locations globally, serving it closer to viewers and significantly reducing latency and improving the streaming experience."
    },
    {
      "id": "9",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL performs video encoding and transcoding on VMs. They want to increase performance and manage this process efficiently on Google Cloud.\n\nWhich Google Cloud service is designed for large-scale video processing and transcoding?",
      "options": {
        "a": "Compute Engine VMs with custom scripts",
        "b": "Dataproc",
        "c": "Transcoder API",
        "d": "Cloud Functions"
      },
      "correct_answer": "c",
      "explanation": "The Transcoder API is a managed service specifically designed for video transcoding at scale. It's more efficient and easier to manage than running custom scripts on individual VMs for this purpose."
    },
    {
      "id": "10",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL wants to increase their predictive capabilities during and before races, incorporating various data points like race results, mechanical failures, and crowd sentiment. They want to move their TensorFlow prediction workloads to Google Cloud.\n\nWhich Google Cloud services are suitable for building, training, and deploying their predictive models at scale?",
      "options": {
        "a": "Compute Engine VMs with manually installed TensorFlow",
        "b": "AI Platform (now Vertex AI)",
        "c": "Cloud Functions",
        "d": "BigQuery ML"
      },
      "correct_answer": "b",
      "explanation": "Vertex AI (formerly AI Platform) is Google Cloud's managed machine learning platform. It provides tools and services for building, training, and deploying ML models, including those built with TensorFlow, at scale without managing underlying infrastructure."
    },
    {
      "id": "11",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL generates significant live telemetry data during races that needs real-time processing for predictions and insights. They also need a data mart for processing large volumes of historical race data.\n\nWhich combination of Google Cloud services is best for handling the real-time telemetry stream and the large-scale data mart?",
      "options": {
        "a": "Cloud Storage for streaming, Cloud SQL for data mart.",
        "b": "Cloud Pub/Sub -> Dataflow (Streaming) for real-time, BigQuery for data mart.",
        "c": "Cloud Functions for streaming, Cloud Bigtable for data mart.",
        "d": "Compute Engine for streaming, Cloud Storage for data mart."
      },
      "correct_answer": "b",
      "explanation": "Cloud Pub/Sub is a scalable messaging bus for ingesting high-velocity streams. Dataflow (Streaming) is ideal for real-time processing and analysis of that stream. BigQuery is a petabyte-scale data warehouse perfect for storing and querying large volumes of historical data for the data mart."
    },
    {
      "id": "12",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL wants to enhance global availability and quality of their broadcasts. Their current mission-critical applications run on another public cloud.\n\nWhich Google Cloud service is essential for distributing traffic globally to backend services hosting their streaming platform?",
      "options": {
        "a": "Internal Load Balancing",
        "b": "Network Load Balancing",
        "c": "External HTTP(S) Load Balancing",
        "d": "TCP Proxy Load Balancing"
      },
      "correct_answer": "c",
      "explanation": "External HTTP(S) Load Balancing is a global service that provides a single IP address and distributes HTTP/HTTPS traffic to backends across multiple regions, directing users to the closest healthy backend to minimize latency and enhance global availability."
    },
    {
      "id": "13",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL needs to create a data mart to enable processing of large volumes of historical race data for analysis and trend prediction.\n\nWhich Google Cloud service is best suited as a scalable data warehouse for this purpose?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Bigtable",
        "d": "BigQuery"
      },
      "correct_answer": "d",
      "explanation": "BigQuery is Google Cloud's fully managed, serverless data warehouse, optimized for storing and analyzing massive datasets using SQL, making it the ideal choice for a data mart processing large volumes of race data."
    },
    {
      "id": "14",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL wants to expose their predictive models to partners via APIs. They need a flexible and scalable platform for API management.\n\nWhich Google Cloud service is suitable for managing, securing, and publishing APIs?",
      "options": {
        "a": "Cloud Functions",
        "b": "Cloud Endpoints or Apigee",
        "c": "Cloud Pub/Sub",
        "d": "Service Directory"
      },
      "correct_answer": "b",
      "explanation": "Cloud Endpoints is suitable for managing APIs built on Google Cloud. Apigee is a more comprehensive, full-lifecycle API management platform. Both can be used to publish, secure, and manage APIs exposed to partners."
    },
    {
      "id": "15",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games is building a new FPS game requiring hundreds of simultaneous players in geo-specific digital arenas with minimal latency. They plan to deploy the backend on GKE.\n\nWhich Google Cloud Load Balancer should they use to route players to the closest regional game arenas running on GKE?",
      "options": {
        "a": "Regional Internal HTTP(S) Load Balancer",
        "b": "Global External HTTP(S) Load Balancer",
        "c": "Regional Network Load Balancer",
        "d": "Global External TCP Proxy Load Balancer"
      },
      "correct_answer": "b",
      "explanation": "For a global game with players connecting from anywhere, a Global External HTTP(S) Load Balancer provides a single entry point and routes users to the closest regional backend (GKE cluster) based on proximity and health, minimizing latency."
    },
    {
      "id": "16",
      "category": "Case Study: Mountkirk Games",
      "text": "The new FPS game requires a real-time global leaderboard that displays top players across every active arena and needs strong consistency.\n\nWhich Google Cloud database service is the best fit for this global, strongly consistent, high-throughput leaderboard?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "b",
      "explanation": "Cloud Spanner is a globally distributed, strongly consistent, and highly available relational database. It's uniquely suited for a real-time global leaderboard that requires high throughput, low latency reads/writes, and guaranteed consistency across regions."
    },
    {
      "id": "17",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to dynamically scale their game backend on GKE based on game activity (number of active players/games).\n\nWhich GKE features are essential for achieving dynamic scaling of their application pods and underlying infrastructure?",
      "options": {
        "a": "Horizontal Pod Autoscaler (HPA) and Cluster Autoscaler",
        "b": "Vertical Pod Autoscaler (VPA) and Node Auto-provisioning",
        "c": "Manual scaling of Deployments and fixed-size node pools",
        "d": "PodDisruptionBudgets (PDBs) and DaemonSets"
      },
      "correct_answer": "a",
      "explanation": "HPA automatically scales the number of pods in a Deployment or StatefulSet based on metrics like CPU/memory usage or custom metrics derived from game activity. Cluster Autoscaler automatically adjusts the number of nodes in the GKE cluster's node pools to accommodate the scaling pods."
    },
    {
      "id": "18",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to store game activity logs in structured files for future analysis. The volume of logs is expected to be very high.\n\nWhich Google Cloud service is a scalable and cost-effective solution for storing these large volumes of semi-structured log data?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Storage",
        "c": "Cloud Bigtable",
        "d": "Persistent Disks"
      },
      "correct_answer": "b",
      "explanation": "Cloud Storage is a highly scalable, durable, and cost-effective object storage service suitable for storing large volumes of structured or semi-structured data like game activity logs in files, which can then be processed by services like BigQuery, Dataproc, or Dataflow."
    },
    {
      "id": "19",
      "category": "Case Study: Mountkirk Games",
      "text": "The new game requires server-side GPU processing for rendering graphics for multi-platform support.\n\nHow can Mountkirk Games provision and utilize GPUs within their GKE cluster?",
      "options": {
        "a": "GPUs are automatically available on all GKE node pools.",
        "b": "Configure GKE node pools to use machine types with attached GPUs.",
        "c": "Run a separate cluster of Compute Engine VMs with GPUs and connect to GKE.",
        "d": "GPUs are not supported on GKE."
      },
      "correct_answer": "b",
      "explanation": "GKE allows you to create node pools using Compute Engine machine types that have GPUs attached. You can then configure your application pods to request GPU resources, and Kubernetes will schedule them onto these GPU-enabled nodes."
    },
    {
      "id": "20",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games wants to maintain most permissions and network policies at a higher level than individual projects for their new games, which are in isolated projects nested below a folder.\n\nWhich Google Cloud resource hierarchy feature enables applying policies consistently across multiple projects?",
      "options": {
        "a": "Labels",
        "b": "Folders",
        "c": "Organizations",
        "d": "Projects"
      },
      "correct_answer": "b",
      "explanation": "Folders are used in the Google Cloud resource hierarchy to group projects. Applying IAM policies and Organization Policies at the Folder level ensures that these policies are inherited by all projects within that folder, providing consistent governance and control."
    },
    {
      "id": "21",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to rapidly iterate on game features, including deploying bug fixes and new functionality frequently.\n\nWhich Google Cloud services are key components of a CI/CD pipeline to support rapid iteration and deployment to GKE?",
      "options": {
        "a": "Cloud Storage, Cloud Functions, Cloud Tasks",
        "b": "Cloud Build, Artifact Registry, Cloud Deploy, GKE",
        "c": "Compute Engine, SSH scripts, manual deployments",
        "d": "BigQuery, Dataflow, Dataproc"
      },
      "correct_answer": "b",
      "explanation": "This represents a typical cloud-native CI/CD flow: Cloud Build automates builds and tests, Artifact Registry stores container images, Cloud Deploy manages the release process and deploys to target environments like GKE."
    },
    {
      "id": "22",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth needs to predict and detect vehicle malfunction based on telemetry data. Critical data is real-time, the rest is uploaded daily. They need to process and analyze this data at scale.\n\nWhich Google Cloud services are appropriate for ingesting, processing, and analyzing both the streaming and batch telemetry data?",
      "options": {
        "a": "Real-time: Cloud Functions -> Cloud SQL; Batch: Cloud Storage -> Dataproc.",
        "b": "Real-time: Cloud Pub/Sub -> Dataflow (Streaming) -> BigQuery; Batch: Cloud Storage -> BigQuery or Dataproc.",
        "c": "Real-time: Compute Engine -> Cloud Bigtable; Batch: Transfer Appliance -> Cloud Storage.",
        "d": "Real-time: Cloud IoT Core (deprecated) -> Cloud Functions; Batch: SFTP to Compute Engine."
      },
      "correct_answer": "b",
      "explanation": "Cloud Pub/Sub is best for ingesting high-velocity streaming data. Dataflow (Streaming) is suitable for real-time processing. BigQuery is a scalable data warehouse for real-time analysis and the batch data mart. For batch data uploaded daily, Cloud Storage is the landing zone, and BigQuery or Dataproc can process it."
    },
    {
      "id": "23",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth needs to create a new abstraction layer for HTTP API access to their legacy systems hosted in private data centers, enabling a gradual move to the cloud.\n\nWhich Google Cloud services can help build and manage APIs that connect to on-premises backend systems via Cloud Interconnect?",
      "options": {
        "a": "Cloud Functions and Cloud Tasks",
        "b": "App Engine and Cloud Scheduler",
        "c": "Cloud Endpoints or Apigee, combined with Serverless VPC Access or Hybrid Connectivity.",
        "d": "Cloud Pub/Sub and Dataflow."
      },
      "correct_answer": "c",
      "explanation": "Cloud Endpoints or Apigee are used for API management. To connect these APIs to on-premises backends over the private network, you need Serverless VPC Access (for serverless API implementations like Cloud Functions/Run) or configure the API gateway/proxy (e.g., on GKE/Compute Engine) to use the existing Cloud Interconnect via the VPC network."
    },
    {
      "id": "24",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth wants to modernize their CI/CD pipelines to allow developers to deploy container-based workloads in highly scalable environments.\n\nWhich Google Cloud services should form the basis of their modern CI/CD pipeline for containerized applications?",
      "options": {
        "a": "Jenkins on Compute Engine, Docker Hub, manual `kubectl` deployments.",
        "b": "Cloud Build, Artifact Registry, Cloud Deploy, GKE or Cloud Run.",
        "c": "Cloud Functions, Cloud Tasks, Cloud Scheduler.",
        "d": "App Engine Standard, Cloud Source Repositories."
      },
      "correct_answer": "b",
      "explanation": "Cloud Build automates the build process (including container images). Artifact Registry is the managed container registry. Cloud Deploy orchestrates the continuous delivery process. GKE or Cloud Run are scalable environments for deploying containerized applications."
    },
    {
      "id": "25",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth needs to allow remote developers to be productive without compromising code or data security.\n\nWhich Google Cloud security and identity services can help enable secure remote development access?",
      "options": {
        "a": "Granting broad `editor` roles to developers.",
        "b": "Using Identity-Aware Proxy (IAP) or Context-Aware Access (BeyondCorp) to control access to development environments and tools based on user identity and context.",
        "c": "Opening firewall rules to allow access from any IP address.",
        "d": "Relying solely on VPNs to the corporate network."
      },
      "correct_answer": "b",
      "explanation": "IAP and Context-Aware Access allow you to control access to applications and VMs based on user identity and the context of the request (device, location, etc.), providing a more secure alternative to VPNs or broad firewall rules, enabling secure remote access without exposing resources directly to the public internet."
    },
    {
      "id": "26",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth needs to use cloud-native solutions for keys and secrets management and optimize for identity-based access.\n\nWhich Google Cloud services are designed for secure secrets management and fine-grained identity and access control?",
      "options": {
        "a": "Cloud Storage and Service Accounts",
        "b": "Secret Manager and Cloud KMS for secrets/keys; IAM for identity-based access.",
        "c": "Environment variables and API keys.",
        "d": "Cloud Audit Logs and Security Command Center."
      },
      "correct_answer": "b",
      "explanation": "Secret Manager is the recommended service for storing and managing secrets like API keys and passwords. Cloud KMS is for managing cryptographic keys. IAM is the foundation for identity-based access control across all Google Cloud resources."
    },
    {
      "id": "27",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth wants to improve and standardize tools necessary for application and network monitoring and troubleshooting across their hybrid environment.\n\nWhich Google Cloud service suite provides integrated monitoring, logging, tracing, and error reporting capabilities?",
      "options": {
        "a": "Google Analytics",
        "b": "Security Command Center",
        "c": "Cloud Operations (formerly Stackdriver)",
        "d": "BigQuery"
      },
      "correct_answer": "d",
      "explanation": "Cloud Operations (which includes Cloud Monitoring, Cloud Logging, Cloud Trace, Error Reporting, and Cloud Profiler) provides an integrated suite of tools with dashboards that can correlate metrics, logs, and traces for comprehensive observability and troubleshooting."
    },
    {
      "id": "28",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth needs to create a self-service portal for internal and partner developers to create new projects, request resources for data analytics jobs, and centrally manage access to the API endpoints.\n\nWhich Google Cloud tools or services can facilitate building this self-service capability?",
      "options": {
        "a": "Manually processing requests via email.",
        "b": "Cloud Deployment Manager or Terraform for provisioning, Service Catalog for product offerings, custom application using Google Cloud APIs (e.g., IAM, Resource Manager).",
        "c": "Cloud Shell scripts shared via email.",
        "d": "Google Forms and manual execution."
      },
      "correct_answer": "b",
      "explanation": "IaC tools (Deployment Manager, Terraform) automate resource provisioning. Service Catalog allows you to curate and offer approved solutions (like pre-configured projects or data analytics environments) to users via a portal. A custom application can be built using Google Cloud APIs to tie these together and provide a user-friendly self-service interface for managing projects, resources, and API access."
    },
    {
      "id": "gcp-gen-1",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A large media company needs to build a scalable and cost-effective video processing pipeline on Google Cloud. They receive large video files daily and need to transcode them into multiple formats for streaming. The workload is batch-oriented but requires high throughput.\n\nWhich Google Cloud service is the most appropriate for the video transcoding task?",
      "options": {
        "a": "Cloud Functions",
        "b": "Transcoder API",
        "c": "Dataflow",
        "d": "Compute Engine instances with FFmpeg"
      },
      "correct_answer": "b",
      "explanation": "The Transcoder API is a managed service specifically designed for large-scale video transcoding, offering high throughput and cost-effectiveness compared to managing custom transcoding software on VMs or using general-purpose processing services like Dataflow or Cloud Functions for this specific task."
    },
    {
      "id": "gcp-gen-2",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a globally distributed application that serves dynamic content to users worldwide. You need low latency for users regardless of their location and the ability to handle traffic spikes. The application backend runs on Google Kubernetes Engine (GKE) in multiple regions.\n\nWhich Google Cloud service should you use to route user requests to the closest healthy GKE cluster?",
      "options": {
        "a": "Regional External HTTP(S) Load Balancer",
        "b": "Global External HTTP(S) Load Balancer",
        "c": "Network Load Balancer",
        "d": "Internal HTTP(S) Load Balancer"
      },
      "correct_answer": "b",
      "explanation": "A Global External HTTP(S) Load Balancer provides a single global IP address and routes HTTP/HTTPS traffic to backends in the closest healthy region, minimizing latency for a global user base. Regional load balancers are limited to a single region, Network Load Balancers are for non-HTTP/S traffic, and Internal Load Balancers are for traffic within a VPC."
    },
    {
      "id": "gcp-gen-3",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A financial institution needs to migrate a mission-critical relational database currently running on-premises. The database requires strong consistency globally, high availability (99.999%), and the ability to scale horizontally to handle increasing transaction volume.\n\nWhich Google Cloud database service is the best fit for these requirements?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Bigtable",
        "c": "Cloud Spanner",
        "d": "BigQuery"
      },
      "correct_answer": "c",
      "explanation": "Cloud Spanner is a globally distributed, strongly consistent, and highly available relational database service designed for mission-critical applications. It offers 99.999% availability and horizontal scalability, which Cloud SQL (regional, typically 99.95% or 99.99% regional HA) and NoSQL databases like Bigtable or BigQuery (analytical) do not provide for this use case."
    },
    {
      "id": "gcp-gen-4",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data lake on Google Cloud to store various datasets for future analysis. The data includes structured data from relational databases, semi-structured data like logs, and unstructured data like images and documents. You need a cost-effective and scalable storage solution.\n\nWhich Google Cloud service should be the primary storage layer for this data lake?",
      "options": {
        "a": "BigQuery",
        "b": "Cloud SQL",
        "c": "Cloud Storage",
        "d": "Cloud Filestore"
      },
      "correct_answer": "c",
      "explanation": "Cloud Storage is Google Cloud's highly scalable, durable, and cost-effective object storage service capable of storing vast amounts of data in any format, making it the ideal foundation for a data lake. BigQuery is a data warehouse for analysis, Cloud SQL is relational, and Cloud Filestore is file storage."
    },
    {
      "id": "gcp-gen-5",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company wants to adopt a hybrid cloud strategy. They have existing on-premises infrastructure and need to connect it to Google Cloud with low latency and high bandwidth for applications that will run across both environments. The connection must be private and dedicated.\n\nWhich Google Cloud networking service should you recommend?",
      "options": {
        "a": "Cloud VPN",
        "b": "VPC Network Peering",
        "c": "Shared VPC",
        "d": "Cloud Interconnect (Dedicated or Partner)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Interconnect provides dedicated, private connections with high bandwidth and low latency between on-premises networks and Google Cloud, suitable for demanding hybrid cloud workloads. Cloud VPN uses IPsec over the public internet, offering lower bandwidth and higher latency."
    },
    {
      "id": "gcp-gen-6",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a cost-optimized compute solution for a batch processing workload that can tolerate interruptions. The workload runs periodically and is not time-sensitive.\n\nWhich Compute Engine pricing model is the most cost-effective for this type of workload?",
      "options": {
        "a": "Standard VMs",
        "b": "Preemptible VMs (now Spot VMs)",
        "c": "Sustained Usage Discounts",
        "d": "Committed Use Discounts"
      },
      "correct_answer": "b",
      "explanation": "Spot VMs (formerly Preemptible VMs) offer significant cost savings for fault-tolerant batch jobs that can be interrupted, as they utilize spare Compute Engine capacity."
    },
    {
      "id": "gcp-gen-7",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A mobile gaming company needs a database for user profiles, game state, and leaderboards. The database must handle millions of concurrent users, support real-time updates, and offer flexible schema. High scalability and low management overhead are key.\n\nWhich Google Cloud database service is most suitable?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "c",
      "explanation": "Cloud Firestore is a serverless, NoSQL document database designed for mobile, web, and server development. It offers real-time synchronization, automatic scaling, and a flexible schema, making it ideal for mobile game backends."
    },
    {
      "id": "gcp-gen-8",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data processing pipeline that needs to process large volumes of log data in real-time as it arrives and perform simple transformations before storing it for analysis in BigQuery.\n\nWhich combination of Google Cloud services is appropriate for ingesting and processing this real-time log data stream?",
      "options": {
        "a": "Cloud Storage -> Dataproc",
        "b": "Cloud Pub/Sub -> Cloud Functions",
        "c": "Cloud Pub/Sub -> Dataflow (Streaming)",
        "d": "Cloud Logging -> BigQuery"
      },
      "correct_answer": "c",
      "explanation": "Cloud Pub/Sub is a scalable messaging service for ingesting data streams. Dataflow (Streaming) is a managed service for complex real-time data processing and transformations, making it suitable for processing the log stream before loading into BigQuery. Cloud Logging can ingest logs but Dataflow is better for processing/transformations."
    },
    {
      "id": "gcp-gen-9",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "Your organization uses a Shared VPC network where a central Host Project manages the network, and multiple Service Projects deploy resources into it. You need to grant a service account in a Service Project permission to create and manage Compute Engine instances within a specific subnet of the Shared VPC network.\n\nWhich IAM role should be granted to the Service Project's service account on the Host Project?",
      "options": {
        "a": "`roles/compute.admin`",
        "b": "`roles/compute.networkUser`",
        "c": "`roles/compute.instanceAdmin`",
        "d": "`roles/owner`"
      },
      "correct_answer": "b",
      "explanation": "The `roles/compute.networkUser` role is specifically designed for Shared VPC and grants permissions to create and manage resources (like VMs) within the shared network from a Service Project. Granting `compute.admin` or `owner` on the Host Project would give excessive permissions."
    },
    {
      "id": "gcp-gen-10",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to automate the provisioning of your Google Cloud infrastructure (VPC networks, subnets, firewall rules, VMs) in a declarative and repeatable manner. You want a tool that is widely adopted and supports multiple cloud providers, although your current focus is GCP.\n\nWhich Infrastructure as Code (IaC) tool is a popular choice for this purpose?",
      "options": {
        "a": "Cloud Deployment Manager",
        "b": "gcloud CLI scripts",
        "c": "Terraform",
        "d": "Ansible"
      },
      "correct_answer": "c",
      "explanation": "Terraform is a popular open-source IaC tool that uses a declarative language to provision infrastructure across multiple cloud providers, including Google Cloud. Cloud Deployment Manager is GCP-native, gcloud scripts are procedural, and Ansible is more focused on configuration management."
    },
    {
      "id": "gcp-gen-11",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "Your application running on Compute Engine VMs requires secure storage for sensitive API keys and database credentials. These secrets should not be hardcoded in configuration files or source code.\n\nWhich Google Cloud service is designed for centralized and secure management of secrets?",
      "options": {
        "a": "Cloud Storage",
        "b": "Cloud KMS",
        "c": "Secret Manager",
        "d": "Environment variables"
      },
      "correct_answer": "c",
      "explanation": "Secret Manager is a fully managed service for securely storing, managing, and accessing secrets like API keys, passwords, certificates, and other sensitive data. Cloud KMS is for cryptographic keys, not general secrets."
    },
    {
      "id": "gcp-gen-12",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to configure network access to a fleet of Compute Engine VMs running a web application. You want to allow inbound HTTP traffic only from the internet and deny all other inbound traffic by default. You also need to allow outbound internet access for software updates.\n\nWhich Google Cloud networking construct should you configure?",
      "options": {
        "a": "VPC Network Peering",
        "b": "Routes",
        "c": "Firewall Rules",
        "d": "Network Policy (GKE)"
      },
      "correct_answer": "c",
      "explanation": "VPC Firewall Rules control traffic flow at the instance level based on IP ranges, protocols, ports, and network tags. You can create ingress rules to allow HTTP from `0.0.0.0/0` and egress rules to allow TCP/80,443 to `0.0.0.0/0` for updates, with a default deny implicit or explicit rule."
    },
     {
      "id": "gcp-gen-13",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are deploying a containerized application on Google Cloud and need to select a platform that offers auto-scaling down to zero instances to minimize costs for workloads with intermittent traffic, without managing the underlying VMs or Kubernetes cluster.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Compute Engine Managed Instance Group (MIG)",
        "b": "Google Kubernetes Engine (GKE)",
        "c": "Cloud Run",
        "d": "App Engine Flexible"
      },
      "correct_answer": "c",
      "explanation": "Cloud Run is a fully managed serverless platform for containerized applications that automatically scales based on requests, including scaling down to zero instances, making it very cost-effective for intermittent workloads."
    },
    {
      "id": "gcp-gen-14",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are troubleshooting performance issues in your microservices application running on GKE. Requests are slow, and you suspect a bottleneck in the communication flow between services. You need to visualize the path requests take and identify latency at each step.\n\nWhich Google Cloud service is designed for distributed tracing?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Cloud Logging",
        "c": "Cloud Trace",
        "d": "Cloud Profiler"
      },
      "correct_answer": "c",
      "explanation": "Cloud Trace is a distributed tracing system that collects and visualizes latency data for requests as they propagate through your application, helping you identify performance bottlenecks across services."
    },
    {
      "id": "gcp-gen-15",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your Compute Engine VMs are experiencing high CPU usage, impacting application responsiveness. You need to identify which specific functions or lines of code within your application are consuming the most CPU resources to optimize them.\n\nWhich Google Cloud service can help you analyze CPU and memory usage within your running application code?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Cloud Profiler",
        "c": "Cloud Logging",
        "d": "Error Reporting"
      },
      "correct_answer": "b",
      "explanation": "Cloud Profiler is a statistical profiler that helps you analyze CPU usage and memory allocation in your application code (running on various GCP compute platforms) to pinpoint performance bottlenecks."
    },
    {
      "id": "gcp-gen-16",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You need to analyze your Google Cloud spending to understand cost drivers and identify optimization opportunities. You want to view costs broken down by project, service, and SKU.\n\nWhich Google Cloud tool should you use?",
      "options": {
        "a": "Pricing Calculator",
        "b": "Quotas dashboard",
        "c": "Billing Reports",
        "d": "Cost Recommendations"
      },
      "correct_answer": "c",
      "explanation": "Google Cloud Billing Reports provide detailed breakdowns of your spending by various dimensions (project, service, SKU, region, labels), allowing for deep cost analysis."
    },
    {
      "id": "gcp-gen-17",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You have petabytes of historical data stored in Cloud Storage that needs to be analyzed using complex SQL queries for business intelligence purposes. You need a serverless, highly scalable data warehouse solution.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Bigtable",
        "d": "BigQuery"
      },
      "correct_answer": "d",
      "explanation": "BigQuery is a fully managed, serverless data warehouse optimized for running fast, complex SQL queries over massive datasets, making it ideal for large-scale data analytics and business intelligence."
    },
    {
      "id": "gcp-gen-18",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your security policy requires that all data stored in Cloud Storage buckets must be encrypted at rest using keys that your organization controls and manages.\n\nWhich encryption option should you configure for your Cloud Storage buckets?",
      "options": {
        "a": "Google-managed encryption keys (default)",
        "b": "Customer-managed encryption keys (CMEK)",
        "c": "Customer-supplied encryption keys (CSEK)",
        "d": "Client-side encryption before uploading"
      },
      "correct_answer": "b",
      "explanation": "CMEK allows you to use encryption keys managed within Google Cloud KMS, giving your organization control over key lifecycle and access policies while Google Cloud handles the encryption/decryption process for services like Cloud Storage."
    },
    {
      "id": "gcp-gen-19",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to grant a user the ability to view resources (VMs, buckets, etc.) within a specific Google Cloud project but prevent them from making any changes.\n\nWhich basic IAM role should you assign?",
      "options": {
        "a": "`roles/viewer`",
        "b": "`roles/editor`",
        "c": "`roles/owner`",
        "d": "`roles/compute.viewer`"
      },
      "correct_answer": "a",
      "explanation": "The `roles/viewer` primitive role grants read-only access to all resources within a project, fulfilling the requirement to view resources without making changes. `roles/compute.viewer` is limited to Compute Engine resources."
    },
    {
      "id": "gcp-gen-20",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization handles highly sensitive customer data in services like BigQuery and Cloud Storage. You need to establish security boundaries to prevent data exfiltration, ensuring that data cannot be copied or moved to unauthorized projects or accessed from outside your trusted network perimeter, even if credentials are compromised.\n\nWhich Google Cloud security capability is designed for creating these security perimeters around services?",
      "options": {
        "a": "IAM Conditions",
        "b": "VPC Firewall Rules",
        "c": "Identity-Aware Proxy (IAP)",
        "d": "VPC Service Controls"
      },
      "correct_answer": "d",
      "explanation": "VPC Service Controls allow you to create security perimeters around Google Cloud services to mitigate data exfiltration risks by restricting access to services from within authorized networks and preventing data movement to unauthorized locations."
    },
    {
      "id": "gcp-gen-21",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "Your development team is building a new microservice on Google Cloud. They need to follow best practices for authenticating to other GCP services (like Cloud Storage or Pub/Sub) from their application code running on Compute Engine.\n\nWhat is the recommended method for the application to authenticate without using hardcoded credentials?",
      "options": {
        "a": "Generate and distribute a service account key file to each VM.",
        "b": "Use API keys for authentication.",
        "c": "Assign a service account to the Compute Engine VM and grant it appropriate IAM roles.",
        "d": "Prompt users for their Google account credentials."
      },
      "correct_answer": "c",
      "explanation": "Assigning a service account to a Compute Engine VM and granting that service account the necessary IAM roles is the recommended, secure way for applications running on the VM to authenticate to other GCP services without managing sensitive key files directly on the VM."
    },
    {
      "id": "gcp-gen-22",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "You are setting up a Continuous Integration pipeline for your containerized application on Google Cloud. You need a managed service that can automatically build your container image from source code stored in Cloud Source Repositories whenever a change is pushed.\n\nWhich Google Cloud service is designed for automating builds?",
      "options": {
        "a": "Cloud Deploy",
        "b": "Cloud Build",
        "c": "Cloud Functions",
        "d": "Artifact Registry"
      },
      "correct_answer": "b",
      "explanation": "Cloud Build is a fully managed CI service that can fetch source code from various repositories (including Cloud Source Repositories), execute build steps (like building a Docker image), run tests, and produce artifacts."
    },
    {
      "id": "gcp-gen-23",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application running on GKE is experiencing intermittent failures, and some pods are crashing. You need a way to automatically restart crashing pods and ensure a minimum number of healthy replicas are always running.\n\nWhich Kubernetes feature helps ensure the application remains healthy and available?",
      "options": {
        "a": "Horizontal Pod Autoscaler (HPA)",
        "b": "Readiness and Liveness Probes",
        "c": "PodDisruptionBudget (PDB)",
        "d": "Node Auto-provisioning"
      },
      "correct_answer": "b",
      "explanation": "Readiness and Liveness probes are configured for pods in Kubernetes. Liveness probes detect if a container is still running correctly and can trigger restarts if it fails (self-healing). Readiness probes indicate if a container is ready to serve traffic, used by services and deployments to route requests only to healthy pods."
    },
    {
      "id": "gcp-gen-24",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to deploy a new version of your critical web application with minimal downtime and the ability to quickly roll back to the previous version if issues are discovered after deployment.\n\nWhich deployment strategy is best suited for this scenario?",
      "options": {
        "a": "Rolling Update",
        "b": "Blue/Green Deployment",
        "c": "Canary Deployment",
        "d": "In-place update"
      },
      "correct_answer": "b",
      "explanation": "Blue/Green deployment involves deploying the new version ('Green') alongside the old version ('Blue') and switching traffic instantly. This allows for a very fast rollback to 'Blue' if 'Green' has problems, minimizing downtime."
    },
    {
      "id": "gcp-gen-25",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are investigating a sudden increase in errors reported by your application across multiple microservices. You need a centralized location to view, search, and analyze logs from all your application components and Google Cloud services to identify the root cause.\n\nWhich Google Cloud service provides centralized logging?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Error Reporting",
        "c": "Cloud Logging",
        "d": "Cloud Trace"
      },
      "correct_answer": "c",
      "explanation": "Cloud Logging is a fully managed service for collecting, storing, and analyzing logs from applications and Google Cloud services. It provides a centralized log repository and tools for searching and filtering logs."
    },
    {
      "id": "gcp-gen-26",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare is migrating their relational databases (MySQL, MS SQL Server) to Google Cloud. They need a managed service that reduces administrative overhead like patching and backups, while retaining SQL compatibility.\n\nWhich Google Cloud service is the primary target for these databases?",
      "options": {
        "a": "BigQuery",
        "b": "Cloud Spanner",
        "c": "Cloud SQL",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "c",
      "explanation": "Cloud SQL is Google Cloud's fully managed relational database service, supporting MySQL, PostgreSQL, and SQL Server. It handles administrative tasks and provides regional availability."
    },
    {
      "id": "gcp-gen-27",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare needs to implement a CI/CD pipeline to automate the deployment of their containerized applications to GKE. They require services for source code hosting, automated builds, and container image storage.\n\nWhich combination of Google Cloud services is suitable for this pipeline?",
      "options": {
        "a": "Cloud Source Repositories, Cloud Build, Artifact Registry",
        "b": "GitHub, Jenkins on Compute Engine, Docker Hub",
        "c": "Cloud Storage, Cloud Functions, Cloud Tasks",
        "d": "App Engine, Cloud Deploy, Container Registry"
      },
      "correct_answer": "a",
      "explanation": "Cloud Source Repositories for Git hosting, Cloud Build for automated builds (including containers), and Artifact Registry (the successor to Container Registry) for storing container images form a standard Google Cloud native CI pipeline."
    },
    {
      "id": "gcp-gen-28",
      "category": "Case Study: Helicopter Racing League (HRL)",
      "text": "HRL wants to improve the global delivery of their video streams to reduce latency for viewers. They need to cache video content at edge locations close to their audience worldwide.\n\nWhich Google Cloud service should they integrate?",
      "options": {
        "a": "Cloud Storage (Nearline)",
        "b": "Cloud CDN",
        "c": "Global External HTTP(S) Load Balancer",
        "d": "Transcoder API"
      },
      "correct_answer": "b",
      "explanation": "Cloud CDN (Content Delivery Network) caches content at Google's global edge locations, reducing latency for users by serving content from a location geographically closer to them. This is ideal for distributing video streams."
    },
    {
      "id": "gcp-gen-29",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games requires a database for a global leaderboard that needs to be updated frequently and provide strongly consistent reads worldwide with very low latency for millions of players.\n\nWhich Google Cloud database service is the best fit?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Firestore",
        "c": "Cloud Bigtable",
        "d": "Cloud Spanner"
      },
      "correct_answer": "d",
      "explanation": "Cloud Spanner is a globally distributed, strongly consistent, and highly available relational database designed for mission-critical applications requiring both relational semantics and global scale with low latency reads/writes."
    },
    {
      "id": "gcp-gen-30",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth has a large fleet of heavy equipment generating telemetry data. They need to ingest this high-volume, high-velocity streaming data for real-time processing and analysis.\n\nWhich Google Cloud service is designed for scalable, real-time messaging and data ingestion?",
      "options": {
        "a": "Cloud Storage",
        "b": "Cloud Tasks",
        "c": "Cloud Pub/Sub",
        "d": "Cloud Scheduler"
      },
      "correct_answer": "c",
      "explanation": "Cloud Pub/Sub is a scalable, asynchronous messaging service that is ideal for ingesting high-volume data streams from many sources, such as IoT devices or vehicle telemetry."
    },
    {
      "id": "gcp-gen-31",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a scalable backend for a web application using serverless compute that can handle variable traffic and scale down to zero when idle to minimize costs. The application logic is stateless.\n\nWhich Google Cloud serverless compute option is most suitable?",
      "options": {
        "a": "Compute Engine MIG with autoscaling",
        "b": "Google Kubernetes Engine (GKE)",
        "c": "Cloud Functions",
        "d": "Cloud Run"
      },
      "correct_answer": "d",
      "explanation": "Cloud Run is a serverless platform for stateless containers that scales automatically based on requests and can scale down to zero, making it very cost-effective for variable, request-driven workloads."
    },
    {
      "id": "gcp-gen-32",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company is migrating a legacy application to Google Cloud using a 'lift-and-shift' strategy. The application runs on VMs with specific OS and software configurations that you want to preserve initially.\n\nWhich Google Cloud migration tool is designed to facilitate migrating VMs with minimal changes?",
      "options": {
        "a": "Migrate to Containers",
        "b": "Transfer Appliance",
        "c": "Migrate to Virtual Machines",
        "d": "Database Migration Service (DMS)"
      },
      "correct_answer": "c",
      "explanation": "Migrate to Virtual Machines is specifically designed for migrating VMs from on-premises or other clouds to Compute Engine with minimal changes to the guest OS or application."
    },
    {
      "id": "gcp-gen-33",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to store large amounts of unstructured data, such as backups and archives, for long-term retention and compliance. This data is accessed very infrequently (less than once a year), and cost is a major factor.\n\nWhich Google Cloud Storage class is the most cost-effective for this use case?",
      "options": {
        "a": "Standard",
        "b": "Nearline",
        "c": "Coldline",
        "d": "Archive"
      },
      "correct_answer": "d",
      "explanation": "Archive storage is the most cost-effective Cloud Storage class for data accessed less than once a year, making it suitable for long-term archives and compliance storage."
    },
    {
      "id": "gcp-gen-34",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are configuring network security for a multi-tier application in your VPC. You have a web tier and an application tier on separate subnets, and you need to restrict traffic so that the web tier can only communicate with the application tier on specific ports, and the application tier cannot directly access the internet. All traffic within a tier should be allowed.\n\nWhich Google Cloud networking feature is used to define these granular traffic control policies?",
      "options": {
        "a": "VPC Network Peering",
        "b": "Shared VPC",
        "c": "Firewall Rules",
        "d": "Routes"
      },
      "correct_answer": "c",
      "explanation": "VPC Firewall Rules allow you to define ingress and egress rules based on source/destination IP ranges, network tags (which you'd apply to VMs in each tier), protocols, and ports, providing granular control over traffic flow between different parts of your network."
    },
    {
      "id": "gcp-gen-35",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to provision and manage a fleet of identical Compute Engine VMs using an automated approach. You want to define the VM configuration (machine type, image, disks, metadata) in a reusable template.\n\nWhich Compute Engine feature should you use?",
      "options": {
        "a": "Snapshots",
        "b": "Instance Templates",
        "c": "Managed Instance Groups (MIGs)",
        "d": "Custom Images"
      },
      "correct_answer": "b",
      "explanation": "Instance Templates are used to define the configuration for creating VMs. Managed Instance Groups use Instance Templates to create and manage pools of identical VMs, but the template itself is the definition."
    },
    {
      "id": "gcp-gen-36",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are monitoring your Cloud SQL instances and notice high latency for read operations. To improve read performance and distribute read traffic, you want to create read-only copies of your primary instance.\n\nWhich Cloud SQL feature should you configure?",
      "options": {
        "a": "High Availability (HA)",
        "b": "Cross-region replication",
        "c": "Read Replicas",
        "d": "Database Migration Service (DMS)"
      },
      "correct_answer": "c",
      "explanation": "Cloud SQL Read Replicas provide read-only copies of a primary instance. Applications can direct read traffic to these replicas, reducing the load on the primary and improving read performance and scalability."
    },
    {
      "id": "gcp-gen-37",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to enforce fine-grained access control to Google Cloud resources based on user identity, device security status, and location, without relying solely on network perimeters like VPNs.\n\nWhich security concept is this approach based on, and which Google Cloud capability is relevant?",
      "options": {
        "a": "Separation of Duties (SoD) with IAM Roles",
        "b": "Defense in Depth with VPC Firewall Rules",
        "c": "Zero Trust / BeyondCorp with Context-Aware Access",
        "d": "Data Loss Prevention (DLP) with Security Command Center"
      },
      "correct_answer": "c",
      "explanation": "The Zero Trust security model (exemplified by Google's BeyondCorp) assumes no network is inherently trusted. Context-Aware Access is a Google Cloud capability that implements Zero Trust principles by granting access based on user identity and the context of the request (device, location, etc.), not just network origin."
    },
    {
      "id": "gcp-gen-38",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "Your data engineering team needs to interact with Cloud Storage buckets from Python scripts running on Compute Engine. They need to upload, download, and list objects programmatically.\n\nWhich Google Cloud client library should they use?",
      "options": {
        "a": "google-api-python-client",
        "b": "google-cloud-storage",
        "c": "google-cloud-core",
        "d": "google-auth"
      },
      "correct_answer": "b",
      "explanation": "The `google-cloud-storage` Python client library provides an idiomatic way to interact with the Cloud Storage service from Python applications."
    },
    {
      "id": "gcp-gen-39",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application is experiencing a sudden surge in errors. You need to quickly identify the type, frequency, and details of application errors occurring across your services to diagnose the problem.\n\nWhich Google Cloud service automatically aggregates and analyzes application errors?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Cloud Logging",
        "c": "Error Reporting",
        "d": "Cloud Profiler"
      },
      "correct_answer": "c",
      "explanation": "Error Reporting automatically counts, aggregates, and analyzes application errors from various sources, providing a clear view of error trends and details to aid in debugging."
    },
    {
      "id": "gcp-gen-40",
      "category": "Case Study: EHR Healthcare",
      "text": "EHR Healthcare needs to store sensitive patient data in Google Cloud, requiring strong compliance with healthcare regulations. They must ensure data is encrypted at rest and that access is strictly controlled based on user roles and compliance status.\n\nWhich combination of Google Cloud services and features is critical for meeting these requirements?",
      "options": {
        "a": "Default Google-managed encryption and basic IAM roles.",
        "b": "Customer-Managed Encryption Keys (CMEK), fine-grained IAM policies, and Cloud Audit Logs.",
        "c": "Network firewalls and Cloud VPN.",
        "d": "Cloud Storage Standard class and Identity Platform."
      },
      "correct_answer": "b",
      "explanation": "CMEK provides control over encryption keys for compliance. Fine-grained IAM policies enforce least privilege access. Cloud Audit Logs provide an immutable record of access for auditing. These are essential for handling sensitive regulated data like EHR."
    },
    {
      "id": "gcp-gen-41",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data warehouse solution for a retail company. They have transactional data from various sources that needs to be ingested, transformed, and loaded for analytical querying. The dataset is large and grows rapidly. You need a serverless service that can handle ETL/ELT processes and support complex joins and aggregations.\n\nWhich Google Cloud service is the best fit for the data warehousing and analytical querying task?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "BigQuery",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "c",
      "explanation": "BigQuery is a fully managed, serverless data warehouse designed for large-scale data analytics. It excels at storing and querying petabytes of data using SQL and is suitable for ETL/ELT pipelines feeding into it."
    },
    {
      "id": "gcp-gen-42",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company needs to host an application that requires a shared file system accessible by multiple Compute Engine VMs simultaneously. The application needs standard file system semantics like locking.\n\nWhich Google Cloud service provides managed NFS file shares?",
      "options": {
        "a": "Cloud Storage",
        "b": "Persistent Disks",
        "c": "Cloud Filestore",
        "d": "Google Drive"
      },
      "correct_answer": "c",
      "explanation": "Cloud Filestore is Google Cloud's managed Network Attached Storage (NAS) service, providing NFS file shares that can be mounted and accessed by multiple Compute Engine VMs or GKE clusters, supporting traditional file system semantics."
    },
    {
      "id": "gcp-gen-43",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to automate the patching and updates of the operating systems on a fleet of Compute Engine VMs across your organization. You want a centralized way to schedule patching windows and monitor compliance.\n\nWhich Google Cloud service is designed for OS patch management?",
      "options": {
        "a": "Cloud Build",
        "b": "Deployment Manager",
        "c": "OS Patch Management",
        "d": "Compute Engine sole-tenant nodes"
      },
      "correct_answer": "c",
      "explanation": "OS Patch Management is a service within Compute Engine that automates the patching process for VMs, allowing you to create patch deployments, target VMs, and view patch compliance."
    },
    {
      "id": "gcp-gen-44",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "A developer needs temporary access to a production Google Cloud project to troubleshoot an issue. Granting a permanent IAM role is against security policy.\n\nWhich IAM feature allows granting time-bound access?",
      "options": {
        "a": "Service Accounts",
        "b": "IAM Recommender",
        "c": "Conditional IAM Bindings",
        "d": "Organization Policies"
      },
      "correct_answer": "c",
      "explanation": "IAM Conditions allow you to add conditions to IAM role bindings, such as time-based conditions, granting principals access only within a specified time window."
    },
    {
      "id": "gcp-gen-45",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are implementing a release process for a critical service where you want to gradually expose a new version to a small percentage of users first to monitor its performance and stability before rolling it out to the entire user base.\n\nWhich deployment strategy does this describe?",
      "options": {
        "a": "Rolling Update",
        "b": "Blue/Green Deployment",
        "c": "Canary Deployment",
        "d": "A/B Testing"
      },
      "correct_answer": "c",
      "explanation": "Canary deployment involves releasing a new version to a small, controlled subset of users to test it in production before performing a full rollout, minimizing the risk of impacting all users."
    },
    {
      "id": "gcp-gen-46",
      "category": "Case Study: Mountkirk Games",
      "text": "Mountkirk Games needs to manage user identities and authentication for their mobile game with millions of users. They need to support sign-in with Google, Facebook, and custom credentials, and provide secure token management for backend API access.\n\nWhich Google Cloud service is designed for customer identity and access management (CIAM)?",
      "options": {
        "a": "Cloud IAM",
        "b": "Identity Platform (Firebase Authentication)",
        "c": "Cloud Identity",
        "d": "Managed Service for Microsoft Active Directory"
      },
      "correct_answer": "b",
      "explanation": "Identity Platform (which includes Firebase Authentication features) is Google Cloud's service for managing customer identities, supporting various authentication methods and integrating with popular identity providers, suitable for large-scale consumer applications."
    },
    {
      "id": "gcp-gen-47",
      "category": "Case Study: TerramEarth",
      "text": "TerramEarth has legacy applications in their private data centers that need to securely expose APIs to partners over their existing Cloud Interconnect connection. They need a managed service to create, secure, and publish these APIs.\n\nWhich Google Cloud service is suitable for API management?",
      "options": {
        "a": "Cloud Functions",
        "b": "Cloud Endpoints or Apigee",
        "c": "Cloud Tasks",
        "d": "Service Directory"
      },
      "correct_answer": "b",
      "explanation": "Cloud Endpoints and Apigee are Google Cloud's primary API management services. Cloud Endpoints is simpler for building APIs on GCP infrastructure, while Apigee is a full-lifecycle platform. Both can be used to expose APIs securely."
    },
    {
      "id": "gcp-gen-48",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a highly available application that can withstand a single zone outage within a Google Cloud region. The application runs on Compute Engine VMs.\n\nWhich deployment strategy should you use for the Compute Engine VMs?",
      "options": {
        "a": "Deploy all VMs in a single zone.",
        "b": "Deploy VMs across multiple regions.",
        "c": "Deploy VMs across multiple zones within the region using a Managed Instance Group (MIG).",
        "d": "Use a single large VM with High Availability extensions."
      },
      "correct_answer": "c",
      "explanation": "To protect against a single zone outage within a region, you must deploy your resources across multiple zones in that region. Using a Managed Instance Group across multiple zones ensures the application remains available even if one zone becomes unavailable."
    },
    {
      "id": "gcp-gen-49",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application logs from various services are scattered. You need to collect, store, and analyze logs from all your Google Cloud resources and custom applications in a centralized location to troubleshoot issues and create log-based metrics.\n\nWhich Google Cloud service should you use?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Error Reporting",
        "c": "Cloud Trace",
        "d": "Cloud Logging"
      },
      "correct_answer": "d",
      "explanation": "Cloud Logging is the centralized service for collecting, storing, and analyzing logs from all Google Cloud services and your custom applications. It allows you to search, filter, and export logs, and create log-based metrics for monitoring and alerting."
    },
    {
      "id": "gcp-gen-50",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to grant a service account the minimum permissions necessary to perform a specific task, such as reading data from a particular Cloud Storage bucket. Granting broader roles like `storage.admin` or `editor` is not permitted due to the principle of least privilege.\n\nWhich IAM role should you assign to the service account on the specific bucket?",
      "options": {
        "a": "`roles/storage.objectViewer`",
        "b": "`roles/storage.admin`",
        "c": "`roles/editor`",
        "d": "`roles/storage.legacyBucketWriter`"
      },
      "correct_answer": "a",
      "explanation": "The `roles/storage.objectViewer` role grants read permissions for objects within a Cloud Storage bucket, adhering to the principle of least privilege for a task that only requires reading data."
    },
    {
      "id": "gcp-gen-51",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A manufacturing company needs to migrate an on-premises application that relies on a shared file system for multiple servers to access common data files. They want a fully managed cloud solution.\n\nWhich Google Cloud service provides a managed file storage service?",
      "options": {
        "a": "Cloud Storage",
        "b": "Persistent Disks",
        "c": "Cloud Filestore",
        "d": "Google Drive"
      },
      "correct_answer": "c",
      "explanation": "Cloud Filestore is Google Cloud's managed NAS (Network Attached Storage) service, providing NFS file shares that can be easily mounted by Compute Engine VMs or GKE clusters, offering a managed solution for shared file system needs."
    },
    {
      "id": "gcp-gen-52",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are using Compute Engine Managed Instance Groups (MIGs) to run a web application. You need to configure the MIG to automatically add or remove VM instances based on the CPU utilization of the existing instances to handle variable load efficiently.\n\nWhich feature of the MIG should you configure?",
      "options": {
        "a": "Instance Template",
        "b": "Health Checks",
        "c": "Autoscaling",
        "d": "Load Balancing"
      },
      "correct_answer": "c",
      "explanation": "Autoscaling is a feature of Managed Instance Groups that allows them to automatically adjust the number of instances in the group based on metrics like CPU utilization, load balancing serving capacity, or Pub/Sub queue size, ensuring the application scales with demand."
    },
    {
      "id": "gcp-gen-53",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You need to monitor the performance and health of your Google Cloud resources (Compute Engine VMs, Cloud SQL instances, load balancers) by collecting metrics, creating dashboards, and setting up alerts when metrics cross predefined thresholds.\n\nWhich Google Cloud service is used for monitoring and alerting?",
      "options": {
        "a": "Cloud Logging",
        "b": "Error Reporting",
        "c": "Cloud Monitoring",
        "d": "Cloud Trace"
      },
      "correct_answer": "c",
      "explanation": "Cloud Monitoring collects metrics from Google Cloud services and applications, allows you to create custom dashboards to visualize these metrics, and enables setting up alerting policies to notify you when metrics exceed thresholds."
    },
    {
      "id": "gcp-gen-54",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization requires that no single individual has excessive permissions that could be misused. For example, the person who can create a cryptographic key should not also be the person who can use it to decrypt sensitive data.\n\nWhich security principle does this requirement align with?",
      "options": {
        "a": "Principle of Least Privilege",
        "b": "Defense in Depth",
        "c": "Separation of Duties (SoD)",
        "d": "Zero Trust"
      },
      "correct_answer": "c",
      "explanation": "Separation of Duties (SoD) is a security principle aimed at preventing fraud and error by ensuring that no single individual has complete control over a critical process. This is often implemented in cloud environments using IAM roles."
    },
    {
      "id": "gcp-gen-55",
      "category": "Syllabus Area 5: Managing implementation",
      "text": "You are helping a team set up a Continuous Delivery pipeline for their application on Google Cloud. After the container image is built and stored in Artifact Registry, you need a managed service to automate the deployment process to target environments like GKE or Cloud Run.\n\nWhich Google Cloud service is designed for continuous delivery?",
      "options": {
        "a": "Cloud Build",
        "b": "Cloud Source Repositories",
        "c": "Cloud Deploy",
        "d": "Cloud Tasks"
      },
      "correct_answer": "c",
      "explanation": "Cloud Deploy is a managed continuous delivery service that automates the deployment of applications to various target environments on Google Cloud, such as GKE, Cloud Run, and App Engine."
    },
    {
      "id": "gcp-gen-56",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application uses a database that needs to be highly available within a single Google Cloud region. If the primary instance fails, a replica should automatically take over to minimize downtime.\n\nWhich Cloud SQL configuration provides high availability within a region?",
      "options": {
        "a": "Read Replicas",
        "b": "Cross-region replication",
        "c": "Regional High Availability (HA)",
        "d": "Database Migration Service (DMS)"
      },
      "correct_answer": "c",
      "explanation": "Configuring a Cloud SQL instance for Regional High Availability (HA) provisions a standby replica in a different zone within the same region. In case of a primary instance failure, Cloud SQL automatically fails over to the standby, providing high availability within that region."
    },
    {
      "id": "gcp-gen-57",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a solution for processing large batch jobs using Apache Spark and Hadoop on Google Cloud. You want a managed service that simplifies cluster creation, management, and scaling.\n\nWhich Google Cloud service is the best fit?",
      "options": {
        "a": "Dataflow",
        "b": "Dataproc",
        "c": "Cloud Composer",
        "d": "BigQuery"
      },
      "correct_answer": "b",
      "explanation": "Dataproc is a managed service for running Apache Spark, Hadoop, and other big data frameworks on Google Cloud. It simplifies the deployment and management of clusters for batch processing."
    },
    {
      "id": "gcp-gen-58",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to comply with regulations that require sensitive data stored in Google Cloud to be protected using hardware security modules (HSMs) certified to FIPS 140-2 Level 3.\n\nWhich Google Cloud service provides managed HSMs?",
      "options": {
        "a": "Secret Manager",
        "b": "Cloud KMS (Software keys)",
        "c": "Cloud HSM",
        "d": "VPC Service Controls"
      },
      "correct_answer": "c",
      "explanation": "Cloud HSM is a fully managed cloud-hosted hardware security module (HSM) service that provides cryptographic key operations within FIPS 140-2 Level 3 certified HSMs."
    },
    {
      "id": "gcp-gen-59",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to understand the performance characteristics of your running application code (CPU usage, memory allocation) to identify bottlenecks for optimization. The application runs on Compute Engine VMs and GKE pods.\n\nWhich Google Cloud service can provide continuous profiling of your code?",
      "options": {
        "a": "Cloud Monitoring",
        "b": "Cloud Logging",
        "c": "Cloud Trace",
        "d": "Cloud Profiler"
      },
      "correct_answer": "d",
      "explanation": "Cloud Profiler is a statistical profiler that continuously analyzes the performance of your application code, helping you pinpoint functions that consume the most CPU or memory."
    },
    {
      "id": "gcp-gen-60",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data pipeline that needs to orchestrate complex workflows involving multiple steps, such as extracting data from various sources, transforming it using Dataflow, and loading it into BigQuery. You need a managed service to define, schedule, and monitor these workflows programmatically.\n\nWhich Google Cloud service is suitable for orchestrating data pipelines?",
      "options": {
        "a": "Cloud Tasks",
        "b": "Cloud Scheduler",
        "c": "Cloud Data Fusion",
        "d": "Cloud Composer (managed Apache Airflow)"
      },
      "correct_answer": "d",
      "explanation": "Cloud Composer is a managed Apache Airflow service that allows you to author, schedule, and monitor complex data pipelines as directed acyclic graphs (DAGs), making it ideal for orchestrating multi-step data workflows."
    },
    {
      "id": "gcp-gen-61",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your security team wants to establish a policy at the organization level that restricts the creation of Compute Engine VMs to only use specific approved OS images.\n\nWhich Google Cloud feature allows you to enforce such constraints across your organization or folders?",
      "options": {
        "a": "IAM Policies",
        "b": "VPC Firewall Rules",
        "c": "Organization Policy Constraints",
        "d": "Security Command Center"
      },
      "correct_answer": "c",
      "explanation": "Organization Policies allow you to define constraints that apply across your Google Cloud organization, folders, or projects, such as restricting allowed VM images using the `constraints/compute.allowedVmImages` constraint."
    },
    {
      "id": "gcp-gen-62",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to migrate a large dataset (hundreds of terabytes) from your on-premises data center to Cloud Storage. Your internet connection is slow and unreliable for such a large transfer.\n\nWhich Google Cloud service or appliance is designed for large-scale offline data transfer?",
      "options": {
        "a": "Storage Transfer Service",
        "b": "gsutil command-line tool",
        "c": "Transfer Appliance",
        "d": "Data Transfer Service for BigQuery"
      },
      "correct_answer": "c",
      "explanation": "Transfer Appliance is a physical appliance that Google Cloud ships to your data center. You load your data onto it and ship it back to Google for offline import into Cloud Storage, bypassing network limitations for very large datasets."
    },
    {
      "id": "gcp-gen-63",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are managing a Cloud SQL database and observe high CPU utilization and slow query execution times. You have already identified the queries causing issues. To improve performance, you should first focus on:\n\nWhich optimization step is typically the first to consider for slow database queries?",
      "options": {
        "a": "Scaling up the Cloud SQL instance machine type.",
        "b": "Adding read replicas.",
        "c": "Optimizing the slow queries and adding appropriate indexes.",
        "d": "Migrating to Cloud Spanner."
      },
      "correct_answer": "c",
      "explanation": "Before scaling infrastructure, the most effective and often cheapest way to improve database performance is to optimize inefficient queries and ensure appropriate indexes are in place to speed up data retrieval. Scaling or migrating might be necessary later, but query tuning comes first."
    },
    {
      "id": "gcp-gen-64",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to discover, classify, and de-identify sensitive data (like PII or credit card numbers) stored in your Google Cloud environment (e.g., in Cloud Storage or BigQuery) to comply with data privacy regulations.\n\nWhich Google Cloud service is designed for identifying and de-identifying sensitive data?",
      "options": {
        "a": "Security Command Center",
        "b": "Cloud Audit Logs",
        "c": "Data Loss Prevention (DLP) API",
        "d": "Cloud Identity"
      },
      "correct_answer": "c",
      "explanation": "The Data Loss Prevention (DLP) API provides powerful tools to scan, discover, classify, and de-identify sensitive data across various Google Cloud services and other data sources."
    },
    {
      "id": "gcp-gen-65",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to implement a disaster recovery (DR) plan for a critical application running in a single Google Cloud region. The Recovery Time Objective (RTO) is 1 hour, and the Recovery Point Objective (RPO) is 15 minutes. You need a strategy where a scaled-down version of the application is running in a secondary region, and data is replicated frequently.\n\nWhich DR pattern does this describe?",
      "options": {
        "a": "Backup and Restore",
        "b": "Pilot Light",
        "c": "Warm Standby",
        "d": "Hot Standby (Multi-region Active/Active)"
      },
      "correct_answer": "c",
      "explanation": "Warm Standby involves maintaining a scaled-down but running replica of the application in the DR region with replicated data, allowing for a relatively fast failover (meeting a 1-hour RTO) and minimizing data loss (meeting a 15-minute RPO). Pilot Light has minimal resources running, Hot Standby has full resources running."
    },
     {
      "id": "gcp-gen-66",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A marketing company needs to analyze user clickstream data in real-time to personalize content on their website. The data is high-velocity and requires processing and analysis with low latency.\n\nWhich combination of Google Cloud services is suitable for ingesting and processing this real-time clickstream data?",
      "options": {
        "a": "Cloud Storage -> BigQuery (batch)",
        "b": "Cloud Pub/Sub -> Dataflow (Streaming) -> BigQuery (streaming inserts)",
        "c": "Cloud SQL -> Cloud Functions",
        "d": "Dataproc (batch) -> BigQuery"
      },
      "correct_answer": "b",
      "explanation": "Cloud Pub/Sub is excellent for ingesting high-velocity streams. Dataflow (Streaming) can process this data in real-time, and BigQuery supports streaming inserts for real-time analysis."
    },
    {
      "id": "gcp-gen-67",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to deploy a containerized application on GKE that requires persistent storage for its data. The data needs to survive pod restarts and rescheduling.\n\nWhich Kubernetes resource should you use to provision persistent storage for your pods on GKE?",
      "options": {
        "a": "ConfigMap",
        "b": "Secret",
        "c": "PersistentVolumeClaim (PVC)",
        "d": "DaemonSet"
      },
      "correct_answer": "c",
      "explanation": "PersistentVolumeClaims (PVCs) are used by pods to request abstract storage resources. Kubernetes then provisions a PersistentVolume (like a Compute Engine Persistent Disk on GKE) that satisfies the claim and makes it available to the pod, ensuring data persistence."
    },
    {
      "id": "gcp-gen-68",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are reviewing your Google Cloud bill and notice unexpectedly high costs for network egress traffic. You need to identify which services and destinations are generating the most outbound traffic from your VPC network to the internet.\n\nWhich Google Cloud service provides detailed network egress cost breakdowns?",
      "options": {
        "a": "Cloud Monitoring (Network metrics)",
        "b": "VPC Flow Logs",
        "c": "Billing Reports",
        "d": "Network Intelligence Center"
      },
      "correct_answer": "c",
      "explanation": "Google Cloud Billing Reports provide the financial breakdown of costs, including network egress, allowing you to filter and group by service, SKU, destination, etc., to understand cost drivers."
    },
    {
      "id": "gcp-gen-69",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to control access to an internal web application running on Compute Engine VMs for employees working remotely without using a traditional VPN. Access should be granted based on the user's identity and whether their device meets security requirements.\n\nWhich Google Cloud service is designed for this context-aware access control?",
      "options": {
        "a": "VPC Firewall Rules",
        "b": "Identity-Aware Proxy (IAP)",
        "c": "Cloud Armor",
        "d": "Cloud VPN"
      },
      "correct_answer": "b",
      "explanation": "Identity-Aware Proxy (IAP) is part of Google's BeyondCorp offering. It controls access to applications based on user identity and context, allowing secure access over the internet without a VPN, enforcing granular policies."
    },
    {
      "id": "gcp-gen-70",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to proactively test the resilience of your application running on GKE by intentionally injecting failures, such as simulating network latency or terminating random pods, to see how the system behaves.\n\nWhich practice involves experimenting on a system to build confidence in its ability to withstand turbulent conditions?",
      "options": {
        "a": "Load Testing",
        "b": "Penetration Testing",
        "c": "Unit Testing",
        "d": "Chaos Engineering"
      },
      "correct_answer": "d",
      "explanation": "Chaos Engineering is the practice of injecting failures into a system to test its resilience and identify weaknesses before they cause outages in production."
    },
    {
      "id": "gcp-gen-71",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A gaming company needs a low-latency database for storing player data that is frequently accessed and updated. The database must be highly scalable and support millions of read and write operations per second. Data consistency is important but eventual consistency might be acceptable for some non-critical data.\n\nWhich Google Cloud NoSQL database service is suitable for high throughput, low latency key-value or wide-column data?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "d",
      "explanation": "Cloud Bigtable is a highly scalable, low-latency NoSQL database designed for large operational and analytical workloads, including time-series and IoT data. It is optimized for high read/write throughput for massive amounts of single-keyed data, making it suitable for gaming data that fits a key-value or wide-column model."
    },
    {
      "id": "gcp-gen-72",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are setting up a hybrid cloud environment and need to ensure that Compute Engine VMs in your VPC can resolve DNS names for resources in your on-premises network using internal IP addresses, and vice-versa.\n\nWhich Google Cloud service is used for managing private DNS zones and enabling hybrid DNS resolution?",
      "options": {
        "a": "Cloud DNS (Public Zones)",
        "b": "Cloud DNS (Private Zones and Peering)",
        "c": "Service Directory",
        "d": "VPC Network Peering"
      },
      "correct_answer": "b",
      "explanation": "Cloud DNS Private Zones allow you to manage internal DNS names within your VPC. DNS peering allows your VPC to query DNS zones in another VPC or on-premises network (via Cloud VPN/Interconnect), enabling hybrid DNS resolution."
    },
     {
      "id": "gcp-gen-73",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a solution for storing and analyzing sensor data arriving from thousands of devices in real-time. The data structure is simple (device ID, timestamp, measurements), and you need to perform aggregations and time-window analysis.\n\nWhich Google Cloud service is well-suited for processing and analyzing real-time data streams?",
      "options": {
        "a": "BigQuery (batch)",
        "b": "Cloud SQL",
        "c": "Dataflow (Streaming)",
        "d": "Dataproc (batch)"
      },
      "correct_answer": "c",
      "explanation": "Dataflow (Streaming) is a fully managed service for both batch and stream processing using the Apache Beam model. It is designed for real-time data processing, transformations, and analysis, making it suitable for streaming sensor data."
    },
    {
      "id": "gcp-gen-74",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization has a multi-project environment in Google Cloud, organized under folders and an organization node. You need to apply consistent IAM policies and security constraints (like requiring specific security features) across multiple projects simultaneously.\n\nWhich feature of the Google Cloud resource hierarchy allows for policy inheritance and centralized governance?",
      "options": {
        "a": "Labels",
        "b": "Projects",
        "c": "Folders and Organization",
        "d": "Service Accounts"
      },
      "correct_answer": "c",
      "explanation": "Policies (IAM and Organization Policies) are inherited down the resource hierarchy from the Organization node to folders and then to projects. Applying policies at higher levels (Organization or Folder) ensures consistent governance across descendant projects."
    },
     {
      "id": "gcp-gen-75",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a highly available application that needs to span multiple Google Cloud regions for disaster recovery. The application uses a globally distributed, strongly consistent relational database.\n\nWhich Google Cloud database service fits this description and supports multi-region deployments for DR?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Firestore",
        "c": "Cloud Bigtable",
        "d": "Cloud Spanner"
      },
      "correct_answer": "d",
      "explanation": "Cloud Spanner is Google Cloud's only globally distributed, strongly consistent relational database service. It is designed for multi-region configurations to provide high availability and disaster recovery across geographic locations."
    },
    {
      "id": "gcp-gen-76",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are analyzing the performance of your web application and discover that static assets (images, CSS, JavaScript) are causing high latency for users in different parts of the world. You need to cache these assets closer to your global users.\n\nWhich Google Cloud service should you use?",
      "options": {
        "a": "Cloud Storage (Standard)",
        "b": "Cloud CDN",
        "c": "Regional External HTTP(S) Load Balancer",
        "d": "Network Service Tiers (Premium Tier)"
      },
      "correct_answer": "b",
      "explanation": "Cloud CDN (Content Delivery Network) caches static and dynamic content at Google's global edge locations, reducing latency for users by serving content from a location geographically closer to them. Network Service Tiers affect routing but not caching."
    },
    {
      "id": "gcp-gen-77",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your application needs to perform cryptographic operations like encryption and decryption using keys that are managed within Google Cloud. You need a managed service that provides secure key management and integrates with other GCP services.\n\nWhich Google Cloud service should you use?",
      "options": {
        "a": "Secret Manager",
        "b": "Cloud KMS",
        "c": "VPC Service Controls",
        "d": "Identity-Aware Proxy (IAP)"
      },
      "correct_answer": "b",
      "explanation": "Cloud Key Management Service (Cloud KMS) is a managed service for creating, managing, and using cryptographic keys. It integrates with various GCP services to provide encryption at rest and can be used directly by applications for cryptographic operations."
    },
    {
      "id": "gcp-gen-78",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application deployment process on GKE uses rolling updates. You need to ensure that during an update, a minimum number of application pods are always available to handle user traffic, even if some pods are being replaced.\n\nWhich Kubernetes feature helps maintain application availability during voluntary disruptions like rolling updates?",
      "options": {
        "a": "Horizontal Pod Autoscaler (HPA)",
        "b": "Liveness Probe",
        "c": "ReplicaSet",
        "d": "PodDisruptionBudget (PDB)"
      },
      "correct_answer": "d",
      "explanation": "A PodDisruptionBudget (PDB) limits the number of pods of a given application that can be simultaneously disrupted from voluntary disruptions (like rolling updates or node drains), helping to ensure a minimum level of availability."
    },
    {
      "id": "gcp-gen-79",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a system to process financial transactions globally. The system requires a database that offers high throughput, low latency, and ACID transactions with strong consistency across multiple geographic regions.\n\nWhich Google Cloud database service is the most appropriate?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Firestore",
        "c": "Cloud Bigtable",
        "d": "Cloud Spanner"
      },
      "correct_answer": "d",
      "explanation": "Cloud Spanner is designed for mission-critical applications requiring globally distributed consistency and high availability with ACID transactions, making it suitable for financial transaction processing at scale."
    },
    {
      "id": "gcp-gen-80",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You need to collect and store metrics from your custom application running on Compute Engine and Google Cloud services to monitor performance and set up alerts based on custom metrics (e.g., number of logged-in users).\n\nWhich Google Cloud service allows you to ingest and monitor custom metrics?",
      "options": {
        "a": "Cloud Logging",
        "b": "Error Reporting",
        "c": "Cloud Monitoring",
        "d": "Cloud Trace"
      },
      "correct_answer": "c",
      "explanation": "Cloud Monitoring allows you to collect, visualize, and alert on metrics from Google Cloud services and applications. It supports ingesting custom metrics using its API or client libraries."
    },
    {
      "id": "gcp-gen-81",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to ensure that all administrative actions performed on Google Cloud resources (e.g., creating a VM, changing IAM policy) are logged for auditing and compliance purposes.\n\nWhich Google Cloud service automatically records administrative activities?",
      "options": {
        "a": "Security Command Center",
        "b": "Cloud Audit Logs",
        "c": "Data Loss Prevention (DLP) API",
        "d": "Cloud Monitoring"
      },
      "correct_answer": "b",
      "explanation": "Cloud Audit Logs record administrative activities and data access logs for Google Cloud services, providing an audit trail for compliance and security analysis."
    },
    {
      "id": "gcp-gen-82",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are planning to migrate an existing application that uses a traditional relational database with complex schemas and joins. You want to move to a managed service on Google Cloud with minimal application code changes.\n\nWhich Google Cloud database service is the most appropriate target for a lift-and-shift or replatforming of a traditional relational database?",
      "options": {
        "a": "Cloud Firestore",
        "b": "Cloud Bigtable",
        "c": "BigQuery",
        "d": "Cloud SQL"
      },
      "correct_answer": "d",
      "explanation": "Cloud SQL is a managed relational database service supporting popular engines like MySQL, PostgreSQL, and SQL Server. It is the primary target for migrating traditional relational databases to Google Cloud with minimal schema or query changes."
    },
    {
      "id": "gcp-gen-83",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to automate the deployment of infrastructure resources (VMs, networks, etc.) on Google Cloud using a declarative approach defined in configuration files. You are working within a team and need version control and state management for your infrastructure.\n\nWhich Infrastructure as Code (IaC) tool should you use?",
      "options": {
        "a": "gcloud CLI scripts",
        "b": "Cloud Deployment Manager",
        "c": "Ansible",
        "d": "Chef"
      },
      "correct_answer": "b",
      "explanation": "Cloud Deployment Manager is Google Cloud's native IaC service. It allows you to provision and manage resources using declarative configuration files (YAML), supports version control, and manages the state of your deployments."
    },
     {
      "id": "gcp-gen-84",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application generates a large volume of logs. You need to analyze these logs using SQL queries for complex analysis and reporting, such as identifying error trends by service or user activity patterns.\n\nHow can you make your Cloud Logging data queryable using SQL?",
      "options": {
        "a": "Query logs directly in the Cloud Logging Logs Explorer.",
        "b": "Export logs to Cloud Storage and query with Dataproc.",
        "c": "Export logs to BigQuery using a Log Sink.",
        "d": "Use Cloud SQL to store and query logs."
      },
      "correct_answer": "c",
      "explanation": "By configuring a Log Sink in Cloud Logging, you can automatically route logs to BigQuery, where they are stored in tables and can be queried using standard SQL for powerful analysis."
    },
    {
      "id": "gcp-gen-85",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to comply with data residency requirements, ensuring that data for specific workloads remains within a particular geographic region.\n\nWhich aspect of Google Cloud design is crucial for meeting data residency requirements?",
      "options": {
        "a": "Global Load Balancing",
        "b": "Using Customer-Managed Encryption Keys (CMEK)",
        "c": "Selecting the appropriate Google Cloud Region for resource deployment",
        "d": "Implementing VPC Service Controls"
      },
      "correct_answer": "c",
      "explanation": "Deploying resources (like Compute Engine VMs, Cloud Storage buckets, Cloud SQL instances) within a specific Google Cloud Region is fundamental to meeting data residency requirements, as data stored in a region generally stays within that region unless explicitly replicated elsewhere."
    },
    {
      "id": "gcp-gen-86",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to inspect the state of your running application in a production environment to diagnose an issue, but you cannot stop or redeploy the application. You want to view variables and the call stack at specific points in the code.\n\nWhich Google Cloud service is designed for debugging live production applications without stopping them?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Monitoring",
        "c": "Cloud Trace",
        "d": "Cloud Debugger"
      },
      "correct_answer": "d",
      "explanation": "Cloud Debugger allows you to inspect the state of a running application in production by setting snapshots at specific code locations, capturing local variables and the call stack without stopping or significantly slowing down the application."
    },
    {
      "id": "gcp-gen-87",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a high-performance, low-latency application that requires block storage for its data volumes on Compute Engine VMs. The application is sensitive to disk I/O performance.\n\nWhich Persistent Disk type provides the highest performance (IOPS and throughput) for demanding workloads?",
      "options": {
        "a": "Standard Persistent Disk",
        "b": "Balanced Persistent Disk",
        "c": "SSD Persistent Disk",
        "d": "Extreme Persistent Disk"
      },
      "correct_answer": "d",
      "explanation": "Extreme Persistent Disks offer the highest IOPS and throughput among Google Cloud Persistent Disk types, designed for extremely demanding database and application workloads."
    },
    {
      "id": "gcp-gen-88",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are reviewing your Cloud SQL costs and notice that development instances are running 24/7 but are only used during business hours. You want to reduce costs by automatically shutting down these instances when they are not needed.\n\nWhich Cloud SQL feature or associated practice can help automate cost optimization by stopping/starting instances?",
      "options": {
        "a": "Autoscaling",
        "b": "Read Replicas",
        "c": "Scheduling (e.g., using Cloud Scheduler or custom scripts)",
        "d": "High Availability (HA)"
      },
      "correct_answer": "c",
      "explanation": "Cloud SQL instances can be scheduled to start and stop at specific times using features like Cloud Scheduler triggering Cloud Functions or custom scripts, significantly reducing costs for non-production environments that aren't needed around the clock."
    },
    {
      "id": "gcp-gen-89",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to secure communication between your web application running on Compute Engine and backend services running in the same VPC network using internal IP addresses. Traffic should be controlled based on source/destination VMs and ports.\n\nWhich Google Cloud networking feature is used to apply security policies within a VPC network?",
      "options": {
        "a": "Global External HTTP(S) Load Balancer",
        "b": "VPC Network Peering",
        "c": "Firewall Rules",
        "d": "Cloud Armor"
      },
      "correct_answer": "c",
      "explanation": "VPC Firewall Rules are stateful and allow you to define ingress and egress policies within your VPC network based on source/destination IP ranges, tags, service accounts, protocols, and ports, controlling internal communication between VMs."
    },
    {
      "id": "gcp-gen-90",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are responsible for the reliability of a critical service. You define metrics (e.g., latency, error rate, availability) that indicate the service's performance and user satisfaction. You then set targets for these metrics and use them to guide operational decisions and balance reliability work with feature development.\n\nWhich SRE concept involves defining these measurable targets?",
      "options": {
        "a": "Error Budget",
        "b": "Service Level Indicators (SLIs)",
        "c": "Service Level Objectives (SLOs)",
        "d": "Site Reliability Engineering (SRE)"
      },
      "correct_answer": "c",
      "explanation": "Service Level Objectives (SLOs) are target values for service reliability, defined based on Service Level Indicators (SLIs). They represent the desired level of performance that the service aims to achieve and are used to manage risk and prioritize work."
    },
    {
      "id": "gcp-gen-91",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company needs to build a scalable backend for a mobile application. The backend requires a database that supports real-time updates and synchronization across multiple devices, offers offline capabilities, and is serverless to minimize operational overhead.\n\nWhich Google Cloud database service is the best fit?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "c",
      "explanation": "Cloud Firestore is a serverless, NoSQL document database designed for mobile, web, and server development. Its key features include real-time synchronization, offline support, and automatic scaling, making it ideal for mobile backends."
    },
    {
      "id": "gcp-gen-92",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to automate the provisioning of your Google Cloud infrastructure using Python code. You want to define and manage resources programmatically.\n\nWhich tool or library is commonly used for programmatic infrastructure management on Google Cloud using Python?",
      "options": {
        "a": "gcloud CLI",
        "b": "Cloud Deployment Manager (YAML)",
        "c": "Google Cloud Client Libraries for Python",
        "d": "Terraform (HCL)"
      },
      "correct_answer": "c",
      "explanation": "Google Cloud Client Libraries provide idiomatic Python libraries to interact with Google Cloud APIs programmatically, allowing you to manage resources directly from your Python code. gcloud is a CLI, Deployment Manager uses YAML, and Terraform uses HCL."
    },
     {
      "id": "gcp-gen-93",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are using BigQuery for large-scale data analytics and observe that some queries are taking a long time to execute. You need to understand the query execution plan and identify which stages are consuming the most time or resources.\n\nWhich BigQuery feature helps you analyze query performance?",
      "options": {
        "a": "Query History",
        "b": "Job Information (Query Explanation)",
        "c": "BigQuery Monitoring",
        "d": "BigQuery Audit Logs"
      },
      "correct_answer": "b",
      "explanation": "BigQuery provides detailed Job Information for each query execution, including a Query Explanation plan that shows the stages of the query, how data was processed, and identifies potential bottlenecks."
    },
    {
      "id": "gcp-gen-94",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to store secrets, such as API keys and passwords, securely in Google Cloud. These secrets need to be versioned and have fine-grained access control.\n\nWhich Google Cloud service is designed for this purpose?",
      "options": {
        "a": "Cloud Storage",
        "b": "Cloud KMS",
        "c": "Secret Manager",
        "d": "Identity-Aware Proxy (IAP)"
      },
      "correct_answer": "c",
      "explanation": "Secret Manager is a dedicated service for securely storing, managing, and accessing secrets. It supports versioning, has fine-grained access control via IAM, and integrates with other GCP services."
    },
    {
      "id": "gcp-gen-95",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to set up health checks for your application running on Compute Engine VMs that are part of a Managed Instance Group (MIG) behind a Load Balancer. Health checks should determine if the application is responding correctly on its designated port.\n\nWhy are health checks essential for Load Balancers and MIGs?",
      "options": {
        "a": "They automatically patch the VMs.",
        "b": "They are used by the Load Balancer to send traffic only to healthy instances.",
        "c": "They reduce the load on the backend VMs.",
        "d": "They provide detailed application logs for debugging."
      },
      "correct_answer": "b",
      "explanation": "Health checks are used by Google Cloud Load Balancers and Managed Instance Groups to determine the health of backend instances. Traffic is only sent to healthy instances, and MIGs can use health check status to trigger auto-healing (recreating unhealthy VMs)."
    },
    {
      "id": "gcp-gen-96",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You need to design a serverless application that processes images uploaded to a Cloud Storage bucket. When a new image is uploaded, the application should automatically trigger a function to resize the image.\n\nWhich Google Cloud service is ideal for implementing this event-driven processing logic?",
      "options": {
        "a": "Cloud Run",
        "b": "Cloud Functions",
        "c": "App Engine Standard",
        "d": "Dataflow"
      },
      "correct_answer": "b",
      "explanation": "Cloud Functions is a serverless Function-as-a-Service (FaaS) that executes code in response to events, such as file uploads to Cloud Storage, messages on Pub/Sub, or HTTP requests. This makes it ideal for event-driven workflows like image processing triggered by uploads."
    },
    {
      "id": "gcp-gen-97",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You are using Compute Engine and need to ensure that VMs without external IP addresses can still securely access Google APIs (like Cloud Storage or BigQuery) over Google's private network, rather than requiring a public IP or Cloud VPN.\n\nWhich feature enables private access to Google APIs from within your VPC?",
      "options": {
        "a": "Serverless VPC Access",
        "b": "VPC Network Peering",
        "c": "Private Google Access",
        "d": "Shared VPC"
      },
      "correct_answer": "c",
      "explanation": "Private Google Access allows VMs in a subnet that do not have external IP addresses to reach Google APIs and services using internal IP addresses, routing traffic over Google's private network."
    },
    {
      "id": "gcp-gen-98",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application deployed on GKE consists of multiple microservices. You need to understand the dependencies between these services and monitor their health and performance from a service-centric view.\n\nWhich Google Cloud service provides insights into your microservice architecture, including service graphs and health metrics?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Trace",
        "c": "Cloud Monitoring (Service Monitoring)",
        "d": "Error Reporting"
      },
      "correct_answer": "c",
      "explanation": "Cloud Monitoring's Service Monitoring feature provides visibility into microservice architectures, automatically generating service maps and displaying key metrics like latency, error rate, and traffic for each service."
    },
    {
      "id": "gcp-gen-99",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization uses Google Cloud and needs a centralized platform to gain visibility into their security posture, identify vulnerabilities, detect threats, and monitor compliance findings across their GCP resources.\n\nWhich Google Cloud service provides this centralized security and data risk management capability?",
      "options": {
        "a": "Cloud Audit Logs",
        "b": "IAM",
        "c": "VPC Service Controls",
        "d": "Security Command Center (SCC)"
      },
      "correct_answer": "d",
      "explanation": "Security Command Center is Google Cloud's comprehensive security and data risk platform that helps users understand their security and data risk surface, detect threats, and monitor compliance status across their GCP assets."
    },
    {
      "id": "gcp-gen-100",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You are debugging a production issue in your application and need to understand the sequence of events and function calls across multiple services that handled a specific user request.\n\nWhich Google Cloud service is used to trace requests across distributed systems?",
      "options": {
        "a": "Cloud Logging",
        "b": "Error Reporting",
        "c": "Cloud Trace",
        "d": "Cloud Profiler"
      },
      "correct_answer": "c",
      "explanation": "Cloud Trace is a distributed tracing system that visualizes the path and latency of requests as they flow through your application, helping you understand the call graph and identify bottlenecks in distributed systems."
    },
    {
      "id": "gcp-gen-101",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "A data science team needs a scalable platform to run Jupyter notebooks and execute machine learning workloads using frameworks like TensorFlow and PyTorch. They want a managed service that simplifies environment setup.\n\nWhich Google Cloud service is suitable for managed notebook environments and ML development?",
      "options": {
        "a": "Compute Engine VMs",
        "b": "Dataproc",
        "c": "AI Platform (now Vertex AI) Notebooks",
        "d": "Cloud Functions"
      },
      "correct_answer": "c",
      "explanation": "Vertex AI Notebooks (formerly AI Platform Notebooks) provides managed Jupyter notebook instances pre-configured with popular data science and ML frameworks, simplifying environment setup for data scientists and ML engineers."
    },
    {
      "id": "gcp-gen-102",
      "category": "Syllabus Area 2: Managing and provisioning the solution infrastructure",
      "text": "You need to update the OS on a large fleet of Compute Engine VMs in a controlled and automated manner to apply security patches and bug fixes.\n\nWhich Google Cloud service helps automate the process of applying OS patches across VMs?",
      "options": {
        "a": "Instance Templates",
        "b": "Managed Instance Groups (MIGs)",
        "c": "OS Patch Management",
        "d": "Cloud Build"
      },
      "correct_answer": "c",
      "explanation": "OS Patch Management is a service within Compute Engine that allows you to automate the process of scanning, applying, and reporting on OS patches across your VM instances."
    },
     {
      "id": "gcp-gen-103",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are analyzing the cost of your Compute Engine VMs and suspect some instances are over-provisioned for their actual workload. You want recommendations on rightsizing VMs to optimize costs.\n\nWhich Google Cloud tool can provide recommendations for rightsizing Compute Engine instances?",
      "options": {
        "a": "Billing Reports",
        "b": "Cloud Monitoring",
        "c": "Cost Recommendations",
        "d": "Pricing Calculator"
      },
      "correct_answer": "c",
      "explanation": "Google Cloud provides Cost Recommendations (part of the Recommendations Hub) that analyze your resource usage and suggest optimizations, such as rightsizing Compute Engine VMs based on CPU/memory utilization patterns."
    },
    {
      "id": "gcp-gen-104",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your application needs to interact with Google Cloud services using a service account. For security best practices, you want to avoid storing the service account key file directly on the VM or in your code repository.\n\nHow should the application running on a Compute Engine VM authenticate using a service account without a key file?",
      "options": {
        "a": "Embed the service account key directly in the application code.",
        "b": "Store the service account key in Secret Manager and retrieve it at runtime.",
        "c": "Assign the service account to the Compute Engine VM and use Application Default Credentials (ADC).",
        "d": "Use API keys for authentication."
      },
      "correct_answer": "c",
      "explanation": "Assigning a service account to a Compute Engine VM allows applications running on that VM to automatically obtain credentials (using Application Default Credentials - ADC) and authenticate to Google Cloud APIs without needing a separate key file."
    },
    {
      "id": "gcp-gen-105",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to implement a deployment strategy that minimizes the risk of a new version causing a major outage. You want to release the new version to a small, specific group of users first, monitor for errors, and if stable, gradually roll it out to more users.\n\nWhich deployment strategy supports this gradual rollout and risk mitigation?",
      "options": {
        "a": "Rolling Update",
        "b": "Blue/Green Deployment",
        "c": "Canary Deployment",
        "d": "Big Bang Deployment"
      },
      "correct_answer": "c",
      "explanation": "Canary deployment allows you to release a new version to a small percentage of users (the 'canary group'), monitor its performance and error rate, and then either roll it out further or roll back if issues are detected, minimizing the blast radius of a bad deployment."
    },
    {
      "id": "gcp-gen-106",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a serverless application that needs to process tasks asynchronously based on a schedule, such as generating daily reports or sending weekly email summaries.\n\nWhich Google Cloud service is designed for triggering scheduled events?",
      "options": {
        "a": "Cloud Pub/Sub",
        "b": "Cloud Tasks",
        "c": "Cloud Scheduler",
        "d": "Cloud Functions"
      },
      "correct_answer": "c",
      "explanation": "Cloud Scheduler is a fully managed enterprise-grade cron job service that allows you to schedule jobs (sending Pub/Sub messages, making HTTP requests, etc.) at specified times or intervals."
    },
     {
      "id": "gcp-gen-107",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "Your application is experiencing high latency for distributed requests that involve multiple microservices. You need to understand the flow of requests across these services and identify which service is introducing the most latency.\n\nWhich Google Cloud service is used for analyzing request latency across microservices?",
      "options": {
        "a": "Cloud Logging",
        "b": "Cloud Monitoring",
        "c": "Cloud Trace",
        "d": "Error Reporting"
      },
      "correct_answer": "c",
      "explanation": "Cloud Trace is a distributed tracing system that helps you visualize request latency across your microservices architecture, identifying where time is being spent in the request path."
    },
    {
      "id": "gcp-gen-108",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "Your organization needs to create a security perimeter around a set of sensitive Google Cloud services (like BigQuery and Cloud Storage) to prevent data exfiltration, even if a VM inside the perimeter is compromised.\n\nWhich Google Cloud security control is designed to create service perimeters?",
      "options": {
        "a": "IAM Policies",
        "b": "VPC Firewall Rules",
        "c": "VPC Service Controls",
        "d": "Cloud Armor"
      },
      "correct_answer": "c",
      "explanation": "VPC Service Controls allow you to define security perimeters around Google Cloud services. These perimeters prevent data from being moved to unauthorized locations and restrict access from outside the perimeter, providing a strong defense against data exfiltration."
    },
     {
      "id": "gcp-gen-109",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a data processing pipeline that requires complex transformations and aggregations on large datasets. The workload can be either batch or streaming, and you prefer a managed service that abstracts away infrastructure management.\n\nWhich Google Cloud service is a unified batch and stream data processing service?",
      "options": {
        "a": "Dataproc",
        "b": "BigQuery",
        "c": "Dataflow",
        "d": "Cloud Composer"
      },
      "correct_answer": "c",
      "explanation": "Dataflow is a fully managed service for executing Apache Beam pipelines on Google Cloud. It supports both batch and stream processing with automatic scaling, making it suitable for complex data transformations."
    },
    {
      "id": "gcp-gen-110",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "You need to implement a deployment strategy that involves deploying a new version of your application alongside the old version. Once the new version is verified, traffic is switched instantly to the new version. This allows for a very fast rollback if needed.\n\nWhich deployment strategy does this describe?",
      "options": {
        "a": "Rolling Update",
        "b": "Blue/Green Deployment",
        "c": "Canary Deployment",
        "d": "A/B Testing"
      },
      "correct_answer": "b",
      "explanation": "Blue/Green deployment involves running two identical environments, one with the old version ('Blue') and one with the new version ('Green'). Traffic is switched from Blue to Green once Green is ready, allowing for instant rollback by switching traffic back to Blue."
    },
    {
      "id": "gcp-gen-111",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "Your company needs a relational database on Google Cloud that offers regional availability and can be configured for high availability within that region with automatic failover.\n\nWhich Google Cloud database service is the primary managed relational database offering with regional HA?",
      "options": {
        "a": "Cloud Spanner",
        "b": "Cloud Firestore",
        "c": "Cloud SQL",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "c",
      "explanation": "Cloud SQL is the primary managed relational database service on Google Cloud. It offers configurations for regional high availability (HA) with automatic failover to a standby replica in another zone within the same region."
    },
    {
      "id": "gcp-gen-112",
      "category": "Syllabus Area 4: Designing for security and compliance",
      "text": "You need to provide a third-party application with programmatic access to a specific Google Cloud resource (e.g., upload files to a bucket). You want to grant permissions specifically to the application, not a human user, and manage these permissions via IAM.\n\nWhich Google Cloud identity type is appropriate for authenticating applications or services?",
      "options": {
        "a": "Google Account",
        "b": "Service Account",
        "c": "Google Group",
        "d": "Google Workspace Account"
      },
      "correct_answer": "b",
      "explanation": "Service accounts are identities used by applications or services to interact with Google Cloud APIs. You create a service account, grant it specific IAM roles on resources, and the application uses the service account's credentials to authenticate."
    },
     {
      "id": "gcp-gen-113",
      "category": "Syllabus Area 1: Designing and planning a cloud solution architecture",
      "text": "You are designing a system for storing time-series data (e.g., sensor readings, metrics) that requires very high write throughput and fast lookups based on a row key (often a combination of identifier and timestamp). The data is non-relational.\n\nWhich Google Cloud NoSQL database service is optimized for high volume, high velocity time-series data?",
      "options": {
        "a": "Cloud SQL",
        "b": "Cloud Spanner",
        "c": "Cloud Firestore",
        "d": "Cloud Bigtable"
      },
      "correct_answer": "d",
      "explanation": "Cloud Bigtable is a managed, scalable NoSQL database designed for large operational and analytical workloads, including time-series data, IoT data, and operational monitoring data. It excels at high write throughput and low-latency lookups by row key."
    },
    {
      "id": "gcp-gen-114",
      "category": "Syllabus Area 3: Analyzing and optimizing technical and business processes",
      "text": "You are analyzing your Google Cloud costs and want to identify resources that are idle or underutilized to reduce spending. You need recommendations on actions you can take to optimize costs.\n\nWhich Google Cloud tool or feature provides cost optimization recommendations?",
      "options": {
        "a": "Billing Reports",
        "b": "Pricing Calculator",
        "c": "Cost Recommendations (Recommendations Hub)",
        "d": "Cloud Monitoring"
      },
      "correct_answer": "c",
      "explanation": "Google Cloud's Cost Recommendations (found in the Recommendations Hub) analyze your usage patterns and provide specific recommendations for cost optimization, such as deleting idle resources, rightsizing VMs, or leveraging committed use discounts."
    },
    {
      "id": "gcp-gen-115",
      "category": "Syllabus Area 6: Ensuring solution and operations reliability",
      "text": "Your application running on Compute Engine VMs needs to be highly available. You have configured a Managed Instance Group (MIG) across multiple zones. You also need to configure checks that verify if each VM instance is healthy and able to serve traffic, so the MIG can recreate unhealthy instances.\n\nWhich feature is used by MIGs to automatically verify the health of instances and trigger auto-healing?",
      "options": {
        "a": "Autoscaling",
        "b": "Load Balancing (with health checks)",
        "c": "Instance Templates",
        "d": "OS Patch Management"
      },
      "correct_answer": "b",
      "explanation": "Managed Instance Groups integrate with Load Balancing health checks. The Load Balancer performs health checks on the VMs in the MIG, and if an instance fails the health check, the MIG is notified and can automatically recreate that unhealthy instance (auto-healing)."
    }
  ]
}